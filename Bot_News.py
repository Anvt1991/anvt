import logging
import os
import asyncio
# NhÃ³m cÃ¡c import thÆ° viá»‡n bÃªn ngoÃ i
import feedparser
import httpx
import redis.asyncio as aioredis
import google.generativeai as genai
# NhÃ³m import telegram
from telegram import Update, InlineKeyboardMarkup, InlineKeyboardButton
from telegram.ext import Application, CommandHandler, CallbackQueryHandler, ContextTypes, MessageHandler, filters
# NhÃ³m cÃ¡c import khÃ¡c
import re
from urllib.parse import urlparse
import unicodedata
import datetime
import pytz
from typing import Dict, List, Any, Optional
import pickle
from functools import wraps
# Import cho viá»‡c phÃ¡t hiá»‡n tin trÃ¹ng láº·p
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
# Import cho sentiment analysis tiáº¿ng Viá»‡t
import numpy as np
import requests
import json
# Import thÃªm signal Ä‘á»ƒ xá»­ lÃ½ tÃ­n hiá»‡u Ä‘Ã³ng/khá»Ÿi Ä‘á»™ng láº¡i
import signal
import sys
import hashlib

# --- 1. Config & setup ---
class Config:
    BOT_TOKEN = os.getenv("BOT_TOKEN")
    WEBHOOK_URL = os.getenv("WEBHOOK_URL")
    REDIS_URL = os.getenv("REDIS_URL", "redis://localhost")
    DB_URL = os.getenv("DATABASE_URL")
    ADMIN_ID = int(os.getenv("ADMIN_ID", "1225226589"))
    GOOGLE_GEMINI_API_KEY = os.getenv("GOOGLE_GEMINI_API_KEY")
    OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")
    GEMINI_MODEL = os.getenv("GEMINI_MODEL", "gemini-2.5-flash-preview-05-20")
    OPENROUTER_FALLBACK_MODEL = os.getenv("OPENROUTER_FALLBACK_MODEL", "deepseek/deepseek-chat-v3-0324:free")
    GROQ_API_KEY = os.getenv("GROQ_API_KEY")
    GROQ_MODEL = os.getenv("GROQ_MODEL", "deepseek-r1-distill-llama-70b")
    FEED_URLS = [
        # Google News theo tá»« khÃ³a
        "https://news.google.com/rss/search?q=kinh+t%E1%BA%BF&hl=vi&gl=VN&ceid=VN:vi",
        "https://news.google.com/rss/search?q=ch%E1%BB%A9ng+kho%C3%A1n&hl=vi&gl=VN&ceid=VN:vi",
        "https://news.google.com/rss/search?q=v%C4%A9+m%C3%B4&hl=vi&gl=VN&ceid=VN:vi",
        "https://news.google.com/rss/search?q=chi%E1%BA%BFn+tranh&hl=vi&gl=VN&ceid=VN:vi",
        "https://news.google.com/rss/search?q=l%C3%A3i+su%E1%BA%A5t&hl=vi&gl=VN&ceid=VN:vi",
        "https://news.google.com/rss/search?q=fed&hl=vi&gl=VN&ceid=VN:vi",
        "https://news.google.com/rss/search?q=tin+n%C3%B3ng&hl=vi&gl=VN&ceid=VN:vi",
        "https://news.google.com/rss/search?q=%C4%91%E1%BA%A7u+t%C6%B0&hl=vi&gl=VN&ceid=VN:vi",
        "https://news.google.com/rss/search?q=doanh+nghi%E1%BB%87p&hl=vi&gl=VN&ceid=VN:vi",
        # ChÃ­nh trá»‹ tháº¿ giá»›i, quan há»‡ quá»‘c táº¿
        "https://news.google.com/rss/search?q=ch%C3%ADnh+tr%E1%BB%8B+th%E1%BA%BF+gi%E1%BB%9Bi&hl=vi&gl=VN&ceid=VN:vi",
        "https://news.google.com/rss/search?q=geopolitics&hl=vi&gl=VN&ceid=VN:vi",
        "https://news.google.com/rss/search?q=world+politics&hl=vi&gl=VN&ceid=VN:vi",
        "https://news.google.com/rss/search?q=international+relations&hl=vi&gl=VN&ceid=VN:vi",
        # Quá»‘c táº¿ (Google News search cÃ¡c nguá»“n quá»‘c táº¿)
        "https://news.google.com/rss/search?q=site:bloomberg.com+stock+OR+market+OR+finance&hl=vi&gl=VN&ceid=VN:vi",
        "https://news.google.com/rss/search?q=site:ft.com+stock+OR+market+OR+finance&hl=vi&gl=VN&ceid=VN:vi",
        # Bá»• sung cÃ¡c nguá»“n Google News RSS tá»‘i Æ°u
        # Chá»©ng khoÃ¡n Viá»‡t Nam tá»« cÃ¡c bÃ¡o lá»›n
        "https://news.google.com/rss/search?q=chá»©ng+khoÃ¡n+site:cafef.vn&hl=vi&gl=VN&ceid=VN:vi",
        "https://news.google.com/rss/search?q=chá»©ng+khoÃ¡n+site:vnexpress.net&hl=vi&gl=VN&ceid=VN:vi",
        # ChÃ­nh sÃ¡ch vÄ© mÃ´
        "https://news.google.com/rss/search?q=chÃ­nh+sÃ¡ch+vÄ©+mÃ´&hl=vi&gl=VN&ceid=VN:vi",
        "https://news.google.com/rss/search?q=lÃ£i+suáº¥t+site:sbv.gov.vn&hl=vi&gl=VN&ceid=VN:vi",
        # Biáº¿n Ä‘á»™ng tháº¿ giá»›i, tÃ i chÃ­nh quá»‘c táº¿
        "https://news.google.com/rss/search?q=market+crash&hl=vi&gl=VN&ceid=VN:vi",
        "https://news.google.com/rss/search?q=site:reuters.com+economy+OR+policy&hl=vi&gl=VN&ceid=VN:vi",
        "https://news.google.com/rss/search?q=site:theguardian.com+world+OR+politics&hl=vi&gl=VN&ceid=VN:vi",
    ]
    REDIS_TTL = int(os.getenv("REDIS_TTL", "60000"))  # 6h
    NEWS_JOB_INTERVAL = int(os.getenv("NEWS_JOB_INTERVAL", "800"))
    HOURLY_JOB_INTERVAL = int(os.getenv("HOURLY_JOB_INTERVAL", "500"))  # ... phÃºt/láº§n
    FETCH_LIMIT_DAYS = int(os.getenv("FETCH_LIMIT_DAYS", "1"))  # Chá»‰ láº¥y tin 1 ngÃ y gáº§n nháº¥t 
    MAX_RETRIES = int(os.getenv("MAX_RETRIES", "3"))  # Sá»‘ láº§n thá»­ láº¡i khi feed lá»—i
    MAX_NEWS_PER_CYCLE = int(os.getenv("MAX_NEWS_PER_CYCLE", "1"))  # Tá»‘i Ä‘a 1 tin má»—i láº§n
    TIMEZONE = pytz.timezone('Asia/Ho_Chi_Minh')  # Timezone chuáº©n cho Viá»‡t Nam
    
    # Cáº¥u hÃ¬nh phÃ¡t hiá»‡n tin trÃ¹ng láº·p - nÃ¢ng cáº¥p
    DUPLICATE_THRESHOLD = float(os.getenv("DUPLICATE_THRESHOLD", "0.65"))  # Äiá»u chá»‰nh ngÆ°á»¡ng phÃ¡t hiá»‡n trÃ¹ng láº·p ná»™i dung
    TITLE_SIMILARITY_THRESHOLD = float(os.getenv("TITLE_SIMILARITY_THRESHOLD", "0.92"))  # NgÆ°á»¡ng phÃ¡t hiá»‡n tiÃªu Ä‘á» tÆ°Æ¡ng tá»±
    LOG_SIMILARITY_DETAILS = os.getenv("LOG_SIMILARITY_DETAILS", "False").lower() == "true"  # Báº­t/táº¯t log chi tiáº¿t vá» similarity
    
    RECENT_NEWS_DAYS = int(os.getenv("RECENT_NEWS_DAYS", "2"))  # Sá»‘ ngÃ y Ä‘á»ƒ láº¥y tin gáº§n Ä‘Ã¢y Ä‘á»ƒ so sÃ¡nh
    
    # Cáº¥u hÃ¬nh phÃ¡t hiá»‡n tin nÃ³ng
    HOT_NEWS_KEYWORDS = [
        "kháº©n cáº¥p", "tin nÃ³ng", "breaking", "khá»§ng hoáº£ng", "crash", "sáº­p", "bÃ¹ng ná»•", "tin nhanh chá»©ng khoÃ¡n", "trÆ°á»›c giá» giao dá»‹ch", 
        "shock", "áº£nh hÆ°á»Ÿng lá»›n", "tháº£m khá»‘c", "tháº£m há»a", "market crash", "sell off", "VNINDEX", "vnindex", "Trump", "fed", "FED",
        "rÆ¡i máº¡nh", "tÄƒng máº¡nh", "giáº£m máº¡nh", "sá»¥p Ä‘á»•", "báº¥t thÆ°á»ng", "emergency", 
        "urgent", "alert", "cáº£nh bÃ¡o", "Ä‘á»™t biáº¿n", "lá»‹ch sá»­", "ká»· lá»¥c", "cao nháº¥t"
    ]
    HOT_NEWS_IMPACT_PHRASES = [
        "tÃ¡c Ä‘á»™ng máº¡nh", "áº£nh hÆ°á»Ÿng nghiÃªm trá»ng", "thay Ä‘á»•i lá»›n", "biáº¿n Ä‘á»™ng máº¡nh",
        "trá»ng Ä‘iá»ƒm", "quan trá»ng", "Ä‘Ã¡ng chÃº Ã½", "Ä‘Ã¡ng lo ngáº¡i", "cáº§n lÆ°u Ã½"
    ]
    
    # Danh sÃ¡ch tá»« khÃ³a lá»c tin tá»©c liÃªn quan (má»Ÿ rá»™ng)
    RELEVANT_KEYWORDS = [
        # ChÃ­nh trá»‹, vÄ© mÃ´, doanh nghiá»‡p, chá»©ng khoÃ¡n, chiáº¿n tranh 
        "chÃ­nh trá»‹", "vÄ© mÃ´", "doanh nghiá»‡p", "chá»©ng khoÃ¡n", "chiáº¿n tranh", "chÃ­nh sÃ¡ch", "lÃ£i suáº¥t", "fed",
        "phe", "Ä‘áº£ng", "chÃ­nh phá»§", "quá»‘c há»™i", "nhÃ  nÆ°á»›c", "bá»™ trÆ°á»Ÿng", "thá»§ tÆ°á»›ng", "chá»§ tá»‹ch",
        # NhÃ³m ngÃ nh, bluechip, midcap, thá»‹ trÆ°á»ng
        "bluechip", "midcap", "ngÃ¢n hÃ ng", "báº¥t Ä‘á»™ng sáº£n", "thÃ©p", "dáº§u khÃ­", "cÃ´ng nghá»‡", "bÃ¡n láº»",
        "xuáº¥t kháº©u", "Ä‘iá»‡n", "xÃ¢y dá»±ng", "thá»§y sáº£n", "dÆ°á»£c pháº©m", "logistics", "váº­n táº£i", 
        # CÃ¡c mÃ£ chá»©ng khoÃ¡n, chá»‰ sá»‘
        "vn30", "hnx", "upcom", "vnindex", "cá»• phiáº¿u", "thá»‹ trÆ°á»ng", "tÃ i chÃ­nh", "kinh táº¿", 
        "gdp", "láº¡m phÃ¡t", "tÃ­n dá»¥ng", "trÃ¡i phiáº¿u", "phÃ¡i sinh", "quá»¹ etf", 
        # CÃ¡c mÃ£ bluechip VN30
        "fpt", "vnm", "vcb", "ssi", "msn", "mwg", "vic", "vhm", "hpg", "ctg", "bid", "mbb", "stb",
        "hdb", "bvh", "vpb", "nvl", "pdr", "tcb", "tpb", "bcm", "pnj", "acb", "vib", "plx",
        # CÃ¡c mÃ£ midcap, cÃ¡c chá»‰ bÃ¡o kinh táº¿
        "vnm", "cpi", "pmi", "m2", "Ä‘áº§u tÆ°", "gdp", "xuáº¥t kháº©u", "nháº­p kháº©u", "dá»± trá»¯", "dá»± bÃ¡o",
        # Tá»« khÃ³a tÃ i chÃ­nh quá»‘c táº¿
        "fed", "ecb", "boj", "pboc", "imf", "world bank", "nasdaq", "dow jones", "s&p", "nikkei",
        "treasury", "usd", "eur", "jpy", "cny", "bitcoin", "crypto", "commodities", "wti", "brent",
        # MÃ£ cá»• phiáº¿u ná»•i báº­t
        "vnd", "ssi", "hpg", "vic", "vhm", "vnm", "mwg", "ctg", "bid", "tcb", "acb", "vib", "stb", "mbb", "shb",
        # TÃªn cÃ´ng ty lá»›n
        "vinamilk", "vietcombank", "vietinbank", "masan", "fpt", "hoa phat", "vietjet", "petro vietnam",
        # Sá»± kiá»‡n kinh táº¿
        "láº¡m phÃ¡t", "tÄƒng trÆ°á»Ÿng", "giáº£m phÃ¡t", "GDP", "CPI", "PMI", "xuáº¥t kháº©u", "nháº­p kháº©u", "tÃ­n dá»¥ng", "trÃ¡i phiáº¿u",
        # Thuáº­t ngá»¯ thá»‹ trÆ°á»ng
        "bull", "bear", "breakout", "margin", "room ngoáº¡i", "ETF", "IPO", "niÃªm yáº¿t", "phÃ¡t hÃ nh", "cá»• tá»©c", "chia thÆ°á»Ÿng",
        # Sá»± kiá»‡n quá»‘c táº¿
        "fed", "ecb", "boj", "nasdaq", "dow jones", "s&p", "nikkei", "usd", "eur", "jpy", "bitcoin", "crypto",
    ]

# Danh sÃ¡ch tá»« khÃ³a bá»• sung
additional_keywords = []

# Danh sÃ¡ch tá»« khÃ³a Ä‘á»ƒ loáº¡i trá»« tin khÃ´ng liÃªn quan
EXCLUDE_KEYWORDS = [
    "khuyáº¿n mÃ£i", "giáº£m giÃ¡", "mua ngay", "tuyá»ƒn dá»¥ng", "sá»± kiá»‡n", "giáº£i trÃ­", "thá»ƒ thao", "lifestyle", 
    "du lá»‹ch", "áº©m thá»±c", "hot deal", "sale off", "quáº£ng cÃ¡o", "Ä‘áº·t hÃ ng", "shoppe", "tiki", "lazada"
]

# --- Kiá»ƒm tra biáº¿n mÃ´i trÆ°á»ng báº¯t buá»™c ---
REQUIRED_ENV_VARS = ["BOT_TOKEN", "OPENROUTER_API_KEY"]
for var in REQUIRED_ENV_VARS:
    if not os.getenv(var):
        raise RuntimeError(f"Missing required environment variable: {var}")

# --- Logging ---
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# --- Redis ---
redis_client = None

# LÆ°u trá»¯ danh sÃ¡ch user Ä‘Ã£ Ä‘Æ°á»£c duyá»‡t
approved_users = set()

# --- Flag Ä‘á»ƒ kiá»ƒm soÃ¡t viá»‡c táº¯t bot ---
shutdown_flag = False

# --- Cleanup function ---
async def cleanup_resources():
    """Dá»n dáº¹p tÃ i nguyÃªn khi bot táº¯t"""
    global redis_client, application
    
    logger.info("Äang dá»n dáº¹p tÃ i nguyÃªn trÆ°á»›c khi táº¯t...")
    
    # Dá»«ng job queue náº¿u Ä‘ang cháº¡y
    if application and application.job_queue:
        logger.info("Dá»«ng job queue...")
        await application.job_queue.stop()
    
    # ÄÃ³ng káº¿t ná»‘i Redis
    if redis_client:
        logger.info("ÄÃ³ng káº¿t ná»‘i Redis...")
        await redis_client.close()
        redis_client = None
    
    logger.info("ÄÃ£ dá»n dáº¹p táº¥t cáº£ tÃ i nguyÃªn.")

# --- Signal handlers ---
def signal_handler(sig, frame):
    """Xá»­ lÃ½ tÃ­n hiá»‡u táº¯t tá»« há»‡ thá»‘ng"""
    global shutdown_flag
    
    if shutdown_flag:
        logger.warning("Nháº­n tÃ­n hiá»‡u táº¯t láº§n hai, táº¯t ngay láº­p tá»©c!")
        sys.exit(1)
    
    logger.info(f"Nháº­n tÃ­n hiá»‡u {sig}, chuáº©n bá»‹ táº¯t bot...")
    shutdown_flag = True
    
    # Cháº¡y cleanup trong asyncio event loop
    try:
        loop = asyncio.get_event_loop()
        if loop.is_running():
            loop.create_task(shutdown())
        else:
            loop.run_until_complete(shutdown())
    except Exception as e:
        logger.error(f"Lá»—i khi dá»n dáº¹p tÃ i nguyÃªn: {e}")
        sys.exit(1)

async def shutdown():
    """Xá»­ lÃ½ shutdown má»™t cÃ¡ch Ä‘á»“ng bá»™"""
    global application
    
    logger.info("Báº¯t Ä‘áº§u quy trÃ¬nh shutdown...")
    
    # Dá»n dáº¹p tÃ i nguyÃªn
    await cleanup_resources()
    
    # Dá»«ng bot náº¿u Ä‘ang cháº¡y
    if application:
        logger.info("Dá»«ng bot...")
        if hasattr(application, 'stop'):
            await application.stop()
        application = None
    
    logger.info("Bot Ä‘Ã£ táº¯t hoÃ n toÃ n.")
    sys.exit(0)

async def is_sent(entry_id):
    return await redis_client.sismember("sent_news", entry_id)

async def mark_sent(entry_id):
    await redis_client.sadd("sent_news", entry_id)
    await redis_client.expire("sent_news", Config.REDIS_TTL)

# --- AI Analysis (Gemini) ---
GEMINI_MODEL = Config.GEMINI_MODEL
OPENROUTER_FALLBACK_MODEL = Config.OPENROUTER_FALLBACK_MODEL
GOOGLE_GEMINI_API_KEY = Config.GOOGLE_GEMINI_API_KEY

async def call_groq_api(prompt, model=None):
    """Gá»i Groq API Ä‘á»ƒ láº¥y káº¿t quáº£ AI phÃ¢n tÃ­ch"""
    api_key = Config.GROQ_API_KEY
    model = model or Config.GROQ_MODEL
    if not api_key:
        raise RuntimeError("GROQ_API_KEY is not set")
    try:
        async with httpx.AsyncClient(timeout=30) as client:
            response = await client.post(
                "https://api.groq.com/openai/v1/chat/completions",
                headers={
                    "Authorization": f"Bearer {api_key}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": model,
                    "messages": [{"role": "user", "content": prompt}],
                    "temperature": 0.7
                }
            )
            result = response.json()
            if "choices" not in result:
                logging.error(f"Groq API error (model={model}): {result}")
                raise RuntimeError(f"Groq API error: {result}")
            return result["choices"][0]["message"]["content"]
    except Exception as e:
        logging.error(f"Groq API lá»—i: {e}")
        raise e

async def analyze_news(prompt, model=None):
    try:
        # Gá»i Google Gemini API chÃ­nh thá»©c
        genai.configure(api_key=GOOGLE_GEMINI_API_KEY)
        model = genai.GenerativeModel("gemini-2.5-flash-preview-04-17")
        response = await asyncio.to_thread(model.generate_content, prompt)
        return response.text
    except Exception as e:
        logging.error(f"Gemini API lá»—i: {e}, fallback sang OpenRouter {OPENROUTER_FALLBACK_MODEL}")
        # Fallback sang OpenRouter
        try:
            async with httpx.AsyncClient(timeout=30) as client:
                response = await client.post(
                    "https://openrouter.ai/api/v1/chat/completions",
                    headers={"Authorization": f"Bearer {os.getenv('OPENROUTER_API_KEY')}",},
                    json={
                        "model": OPENROUTER_FALLBACK_MODEL,
                        "messages": [{"role": "user", "content": prompt}],
                        "temperature": 0.7
                    }
                )
                result = response.json()
                if "choices" not in result:
                    logging.error(f"OpenRouter API error (model={OPENROUTER_FALLBACK_MODEL}): {result}")
                    raise RuntimeError(f"OpenRouter API error: {result}")
                return result["choices"][0]["message"]["content"]
        except Exception as e2:
            logging.error(f"OpenRouter fallback cÅ©ng lá»—i: {e2}, thá»­ tiáº¿p Groq...")
            # Fallback sang Groq
            try:
                return await call_groq_api(prompt)
            except Exception as e3:
                logging.error(f"Groq fallback cÅ©ng lá»—i: {e3}")
                raise e3

# --- Extract sentiment from AI result ---
def extract_sentiment_rule_based(ai_summary):
    """Extract sentiment from AI summary using rule-based approach"""
    sentiment = "Trung láº­p"  # Default
    try:
        # TÃ¬m kiáº¿m dÃ²ng cÃ³ chá»©a 'cáº£m xÃºc'
        for line in ai_summary.splitlines():
            line_lower = line.lower()
            if "cáº£m xÃºc:" in line_lower or "sentiment:" in line_lower:
                sentiment_text = line.split(":")[-1].strip().lower()
                if "tÃ­ch cá»±c" in sentiment_text or "positive" in sentiment_text:
                    return "TÃ­ch cá»±c"
                elif "tiÃªu cá»±c" in sentiment_text or "negative" in sentiment_text:
                    return "TiÃªu cá»±c"
                else:
                    return "Trung láº­p"
        # Náº¿u khÃ´ng tÃ¬m tháº¥y dÃ²ng cáº£m xÃºc, dÃ¹ng regex tÃ¬m toÃ n vÄƒn báº£n
        text = ai_summary.lower()
        if re.search(r"(tÃ­ch cá»±c|positive|láº¡c quan|upbeat|bullish)", text):
            return "TÃ­ch cá»±c"
        elif re.search(r"(tiÃªu cá»±c|negative|bi quan|bearish|lo ngáº¡i|lo láº¯ng)", text):
            return "TiÃªu cá»±c"
    except Exception as e:
        logging.warning(f"Lá»—i khi parse sentiment rule-based: {e}")
    return sentiment

async def extract_sentiment(ai_summary):
    """Extract sentiment from AI summary, chá»‰ sá»­ dá»¥ng rule-based"""
    return extract_sentiment_rule_based(ai_summary)

def is_hot_news(entry, ai_summary, sentiment):
    """PhÃ¡t hiá»‡n tin nÃ³ng dá»±a trÃªn phÃ¢n tÃ­ch ná»™i dung, tá»« khÃ³a vÃ  cáº£m xÃºc"""
    try:
        title = getattr(entry, 'title', '').lower()
        summary = getattr(entry, 'summary', '').lower()
        content_text = f"{title} {summary}".lower()
        
        # 1. Kiá»ƒm tra tá»« khÃ³a tin nÃ³ng trong tiÃªu Ä‘á» hoáº·c ná»™i dung
        for keyword in Config.HOT_NEWS_KEYWORDS:
            if keyword.lower() in content_text:
                logging.info(f"Hot news phÃ¡t hiá»‡n bá»Ÿi tá»« khÃ³a '{keyword}': {title}")
                return True
                
        # 2. Kiá»ƒm tra cÃ¡c cá»¥m tá»« áº£nh hÆ°á»Ÿng trong AI summary
        ai_text = ai_summary.lower()
        for phrase in Config.HOT_NEWS_IMPACT_PHRASES:
            if phrase.lower() in ai_text:
                logging.info(f"Hot news phÃ¡t hiá»‡n bá»Ÿi cá»¥m tá»« áº£nh hÆ°á»Ÿng '{phrase}': {title}")
                return True
        
        # 3. PhÃ¢n tÃ­ch dá»±a trÃªn cáº£m xÃºc vÃ  má»©c Ä‘á»™ áº£nh hÆ°á»Ÿng
        if sentiment != "Trung láº­p":
            # Náº¿u cÃ³ cáº£m xÃºc vÃ  cÃ¡c tá»« chá»‰ má»©c Ä‘á»™ cao trong phÃ¢n tÃ­ch AI
            intensity_words = ["ráº¥t", "máº¡nh", "nghiÃªm trá»ng", "Ä‘Ã¡ng ká»ƒ", "lá»›n", "quan trá»ng"]
            for word in intensity_words:
                if word in ai_text and (
                    "thá»‹ trÆ°á»ng" in ai_text or "nhÃ  Ä‘áº§u tÆ°" in ai_text or "áº£nh hÆ°á»Ÿng" in ai_text
                ):
                    logging.info(f"Hot news phÃ¡t hiá»‡n bá»Ÿi cáº£m xÃºc vÃ  má»©c Ä‘á»™ áº£nh hÆ°á»Ÿng: {title}")
                    return True
        
        return False
    except Exception as e:
        logging.warning(f"Lá»—i khi phÃ¡t hiá»‡n tin nÃ³ng: {e}")
        return False

# --- Parse RSS Feed & News Processing ---
def normalize_text(text):
    if not text:
        return ""
    # Loáº¡i bá» dáº¥u tiáº¿ng Viá»‡t
    text = unicodedata.normalize('NFD', text)
    text = ''.join([c for c in text if unicodedata.category(c) != 'Mn'])
    # Loáº¡i bá» kÃ½ tá»± Ä‘áº·c biá»‡t, chá»‰ giá»¯ láº¡i chá»¯ vÃ  sá»‘
    text = re.sub(r'[^a-zA-Z0-9 ]', '', text)
    # Viáº¿t thÆ°á»ng, loáº¡i bá» khoáº£ng tráº¯ng thá»«a
    text = text.lower().strip()
    return text

def is_recent_news(entry, days=Config.FETCH_LIMIT_DAYS):
    """
    Chá»‰ láº¥y tin cÃ³ ngÃ y Ä‘Äƒng lÃ  hÃ´m nay (theo timezone Viá»‡t Nam).
    Náº¿u khÃ´ng parse Ä‘Æ°á»£c ngÃ y thÃ¬ bá» qua (khÃ´ng láº¥y).
    """
    published = getattr(entry, 'published', None) or getattr(entry, 'updated', None)
    if not published:
        return False
    try:
        # Thá»­ parse nhiá»u Ä‘á»‹nh dáº¡ng ngÃ y thÃ¡ng
        try:
            dt = datetime.datetime.strptime(published, '%a, %d %b %Y %H:%M:%S %Z')
        except ValueError:
            try:
                dt = datetime.datetime.strptime(published, '%a, %d %b %Y %H:%M:%S %z')
            except ValueError:
                # Náº¿u khÃ´ng parse Ä‘Æ°á»£c, bá» qua tin nÃ y
                return False
        # Äáº£m báº£o cÃ³ timezone
        if not dt.tzinfo:
            dt = Config.TIMEZONE.localize(dt)
        now = get_now_with_tz()
        # So sÃ¡nh ngÃ y (khÃ´ng so sÃ¡nh giá»)
        return dt.date() == now.date()
    except Exception as e:
        logger.warning(f"Lá»—i khi kiá»ƒm tra thá»i gian tin: {e}")
        # Náº¿u cÃ³ lá»—i, bá» qua tin nÃ y
        return False

def is_relevant_news_smart(entry):
    """
    Lá»c tin thÃ´ng minh: nhiá»u tá»« khÃ³a liÃªn quan, loáº¡i trá»« spam/PR.
    """
    title = normalize_text(getattr(entry, 'title', ''))
    summary = normalize_text(getattr(entry, 'summary', ''))
    content_text = f"{title} {summary}"

    # Loáº¡i trá»« tin spam/PR
    for ex_kw in EXCLUDE_KEYWORDS:
        if normalize_text(ex_kw) in content_text:
            return False

    # Äáº¿m sá»‘ tá»« khÃ³a liÃªn quan xuáº¥t hiá»‡n
    all_keywords = [normalize_text(k) for k in Config.RELEVANT_KEYWORDS] + [normalize_text(k) for k in additional_keywords]
    match_count = sum(1 for kw in all_keywords if kw and kw in content_text)
    
    # Pháº£i cÃ³ Ã­t nháº¥t 1 tá»« khÃ³a
    return match_count >= 1

def is_hot_news_simple(entry):
    """
    PhÃ¡t hiá»‡n tin nÃ³ng mÃ  khÃ´ng dÃ¹ng AI, chá»‰ dá»±a trÃªn tá»« khÃ³a.
    """
    title = getattr(entry, 'title', '').lower()
    summary = getattr(entry, 'summary', '').lower()
    content_text = f"{title} {summary}".lower()
    
    for keyword in Config.HOT_NEWS_KEYWORDS:
        if keyword.lower() in content_text:
            logger.info(f"Hot news Ä‘Æ¡n giáº£n phÃ¡t hiá»‡n bá»Ÿi tá»« khÃ³a '{keyword}': {title}")
            return True
    
    return False

def is_relevant_news(entry):
    """
    Kiá»ƒm tra xem tin tá»©c cÃ³ liÃªn quan Ä‘áº¿n cÃ¡c chá»§ Ä‘á» quan tÃ¢m khÃ´ng dá»±a trÃªn tá»« khÃ³a (chuáº©n hÃ³a)
    """
    # Láº¥y ná»™i dung tá»« tiÃªu Ä‘á» vÃ  tÃ³m táº¯t, chuáº©n hÃ³a
    title = normalize_text(getattr(entry, 'title', ''))
    summary = normalize_text(getattr(entry, 'summary', ''))
    content_text = f"{title} {summary}"

    # Chuáº©n hÃ³a tá»« khÃ³a máº·c Ä‘á»‹nh vÃ  bá»• sung
    all_keywords = [normalize_text(k) for k in Config.RELEVANT_KEYWORDS] + [normalize_text(k) for k in additional_keywords]

    # So khá»›p tá»« khÃ³a
    for keyword in all_keywords:
        if keyword and keyword in content_text:
            return True
    return False

async def parse_feed(url):
    try:
        feed_data = await asyncio.to_thread(feedparser.parse, url)
        if not feed_data.entries:
            logger.warning(f"KhÃ´ng tÃ¬m tháº¥y tin tá»©c tá»« feed: {url}")
            return []
        return feed_data.entries
    except Exception as e:
        logger.error(f"Lá»—i khi parse RSS feed {url}: {e}")
        return []

def extract_image_url(entry):
    """Extract image URL from entry if available"""
    try:
        if 'media_content' in entry and entry.media_content:
            for media in entry.media_content:
                if 'url' in media:
                    return media['url']
        
        # Try finding image in content
        if 'content' in entry and entry.content:
            for content in entry.content:
                if 'value' in content:
                    match = re.search(r'<img[^>]+src="([^">]+)"', content['value'])
                    if match:
                        return match.group(1)
        
        # Try finding image in summary
        if hasattr(entry, 'summary'):
            match = re.search(r'<img[^>]+src="([^">]+)"', entry.summary)
            if match:
                return match.group(1)
    except Exception as e:
        logger.warning(f"Lá»—i khi extract áº£nh: {e}")
    
    return None
    
# --- Command Handler Functions ---

# Admin only decorator
def admin_only(func):
    @wraps(func)
    async def wrapped(update: Update, context: ContextTypes.DEFAULT_TYPE, *args, **kwargs):
        user_id = update.effective_user.id
        if user_id != Config.ADMIN_ID:
            await update.message.reply_text("âŒ Báº¡n khÃ´ng cÃ³ quyá»n sá»­ dá»¥ng lá»‡nh nÃ y.")
            return
        return await func(update, context, *args, **kwargs)
    return wrapped

# --- Redis-only user approval ---
async def is_user_approved(user_id):
    # LuÃ´n coi ADMIN_ID lÃ  approved, khÃ´ng cáº§n lÆ°u vÃ o Redis
    return user_id == Config.ADMIN_ID or await redis_client.sismember("approved_users", user_id)

# --- User approval logic using Redis set ---
async def approve_user_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    action, user_id = query.data.split("_")
    user_id = int(user_id)
    if action == "approve":
        if user_id != Config.ADMIN_ID:
            await redis_client.sadd("approved_users", user_id)
        await query.edit_message_text(f"âœ… User {user_id} Ä‘Ã£ Ä‘Æ°á»£c phÃª duyá»‡t.")
        await context.bot.send_message(chat_id=user_id, text="âœ… Báº¡n Ä‘Ã£ Ä‘Æ°á»£c phÃª duyá»‡t Ä‘á»ƒ sá»­ dá»¥ng Bot News! GÃµ /help Ä‘á»ƒ xem hÆ°á»›ng dáº«n.")
    else:
        await query.edit_message_text(f"âŒ ÄÃ£ tá»« chá»‘i yÃªu cáº§u tá»« user {user_id}.")
        await context.bot.send_message(chat_id=user_id, text="âŒ YÃªu cáº§u sá»­ dá»¥ng bot cá»§a báº¡n Ä‘Ã£ bá»‹ tá»« chá»‘i.")

# --- LÆ°u vÃ  láº¥y tiÃªu Ä‘á»/tin gáº§n Ä‘Ã¢y báº±ng Redis list (giá»›i háº¡n 200) ---
async def add_recent_title(normalized_title, limit=200):
    await redis_client.lpush("recent_titles", normalized_title)
    await redis_client.ltrim("recent_titles", 0, limit-1)

async def get_recent_titles(limit=200):
    return [title.decode() if isinstance(title, bytes) else title for title in await redis_client.lrange("recent_titles", 0, limit-1)]

async def add_recent_news_text(news_text, limit=200):
    await redis_client.lpush("recent_news_texts", news_text)
    await redis_client.ltrim("recent_news_texts", 0, limit-1)

async def get_recent_news_texts(limit=200):
    return [txt.decode() if isinstance(txt, bytes) else txt for txt in await redis_client.lrange("recent_news_texts", 0, limit-1)]

# --- Registration commands
async def register_user(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user = update.effective_user
    user_id = user.id
    
    # Check if already approved
    if await is_user_approved(user_id):
        await update.message.reply_text("âœ… Báº¡n Ä‘Ã£ Ä‘Æ°á»£c Ä‘Äƒng kÃ½ sá»­ dá»¥ng bot rá»“i!")
        return
    
    # Notify admin about registration request
    keyboard = [
        [
            InlineKeyboardButton("Approve âœ…", callback_data=f"approve_{user_id}"),
            InlineKeyboardButton("Deny âŒ", callback_data=f"deny_{user_id}")
        ]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    await context.bot.send_message(
        chat_id=Config.ADMIN_ID,
        text=(
            f"ğŸ”” YÃªu cáº§u Ä‘Äƒng kÃ½ má»›i:\n"
            f"User ID: {user_id}\n"
            f"Name: {user.first_name} {user.last_name or ''}\n"
            f"Username: @{user.username or 'N/A'}"
        ),
        reply_markup=reply_markup
    )
    
    await update.message.reply_text(
        "ğŸ“ YÃªu cáº§u Ä‘Äƒng kÃ½ cá»§a báº¡n Ä‘Ã£ Ä‘Æ°á»£c gá»­i tá»›i admin. "
        "Báº¡n sáº½ Ä‘Æ°á»£c thÃ´ng bÃ¡o khi yÃªu cáº§u Ä‘Æ°á»£c xá»­ lÃ½."
    )

# --- Timezone Helper Functions ---
def get_now_with_tz():
    """Return current datetime with timezone"""
    return datetime.datetime.now(Config.TIMEZONE)

def format_datetime(dt, format='%Y-%m-%d %H:%M:%S'):
    """Format datetime with timezone if needed"""
    if dt is None:
        return get_now_with_tz().strftime(format)
    
    # Check if datetime has timezone info
    if not dt.tzinfo:
        # Add timezone info if missing
        dt = Config.TIMEZONE.localize(dt)
    
    return dt.strftime(format)

def ensure_timezone_aware(dt):
    """Äáº£m báº£o datetime object cÃ³ timezone trÆ°á»›c khi Ä‘Æ°a vÃ o DB"""
    if dt is None:
        return get_now_with_tz()
    # Náº¿u Ä‘Ã£ cÃ³ tzinfo vÃ  offset, tráº£ vá» nguyÃªn báº£n
    if dt.tzinfo is not None and dt.tzinfo.utcoffset(dt) is not None:
        return dt
    # Náº¿u chÆ°a cÃ³ timezone, thÃªm vÃ o
    try:
        return Config.TIMEZONE.localize(dt)
    except (ValueError, AttributeError):
        # Xá»­ lÃ½ cÃ¡c trÆ°á»ng há»£p ngoáº¡i lá»‡
        logger.warning(f"KhÃ´ng thá»ƒ thÃªm timezone cho datetime: {dt}")
        # Táº¡o má»›i datetime vá»›i timezone
        return datetime.datetime(
            dt.year, dt.month, dt.day, 
            dt.hour, dt.minute, dt.second, 
            dt.microsecond, Config.TIMEZONE
        )

async def normalize_title(title):
    """Chuáº©n hÃ³a tiÃªu Ä‘á» tin tá»©c Ä‘á»ƒ so sÃ¡nh"""
    if not title:
        return ""
    
    # Remove HTML tags if any
    title = re.sub(r'<[^>]+>', '', title)
    
    # Normalize unicode
    title = unicodedata.normalize('NFD', title)
    title = ''.join([c for c in title if unicodedata.category(c) != 'Mn'])
    
    # Convert to lowercase and remove extra spaces
    title = re.sub(r'\s+', ' ', title.lower().strip())
    
    # Remove special characters
    title = re.sub(r'[^\w\s]', '', title)
    
    return title

async def is_title_sent(normalized_title):
    """Kiá»ƒm tra xem tiÃªu Ä‘á» Ä‘Ã£ Ä‘Æ°á»£c gá»­i chÆ°a (dá»±a trÃªn tiÃªu Ä‘á» chuáº©n hÃ³a)"""
    return await redis_client.sismember("sent_titles", normalized_title)

async def mark_title_sent(normalized_title):
    """ÄÃ¡nh dáº¥u tiÃªu Ä‘á» Ä‘Ã£ Ä‘Æ°á»£c gá»­i"""
    await redis_client.sadd("sent_titles", normalized_title)
    await redis_client.expire("sent_titles", Config.REDIS_TTL)

# --- News Deduplication by Hash ---
async def is_hash_sent(content_hash):
    return await redis_client.sismember("sent_hashes", content_hash)

async def mark_hash_sent(content_hash):
    await redis_client.sadd("sent_hashes", content_hash)
    await redis_client.expire("sent_hashes", Config.REDIS_TTL)

def is_similar_title(new_title, recent_titles, threshold=None):
    """So sÃ¡nh tiÃªu Ä‘á» má»›i vá»›i cÃ¡c tiÃªu Ä‘á» cÅ©, náº¿u similarity > threshold thÃ¬ coi lÃ  trÃ¹ng"""
    if not recent_titles:
        return False
        
    # Sá»­ dá»¥ng ngÆ°á»¡ng tá»« Config náº¿u khÃ´ng Ä‘Æ°á»£c chá»‰ Ä‘á»‹nh
    if threshold is None:
        threshold = Config.TITLE_SIMILARITY_THRESHOLD
        
    try:
        titles = [new_title] + recent_titles
        vectorizer = TfidfVectorizer().fit_transform(titles)
        vectors = vectorizer.toarray()
        sim_scores = cosine_similarity([vectors[0]], vectors[1:])[0]
        max_sim = max(sim_scores) if len(sim_scores) > 0 else 0
        
        # Ghi log chi tiáº¿t náº¿u Ä‘Æ°á»£c cáº¥u hÃ¬nh
        if Config.LOG_SIMILARITY_DETAILS and max_sim > 0.6:
            max_idx = sim_scores.argmax() if len(sim_scores) > 0 else -1
            similar_title = recent_titles[max_idx] if max_idx >= 0 else "N/A"
            logger.info(f"Similarity tiÃªu Ä‘á»: {max_sim:.2f} (ngÆ°á»¡ng: {threshold:.2f})")
            logger.debug(f"TiÃªu Ä‘á» má»›i: {new_title[:30]}... | TiÃªu Ä‘á» tÆ°Æ¡ng tá»±: {similar_title[:30]}...")
            
        return max_sim > threshold
    except Exception as e:
        logger.error(f"Lá»—i khi so sÃ¡nh tiÃªu Ä‘á» tÆ°Æ¡ng tá»±: {e}")
        return False

# --- News Duplication Detection ---
def is_duplicate_by_content(new_text, recent_texts, threshold=Config.DUPLICATE_THRESHOLD):
    """
    PhÃ¡t hiá»‡n tin trÃ¹ng láº·p báº±ng TF-IDF vÃ  Cosine Similarity
    NÃ¢ng cáº¥p:
    - Sá»­ dá»¥ng ngram tá»« 1-3 Ä‘á»ƒ báº¯t cá»¥m tá»« dÃ i hÆ¡n
    - Loáº¡i bá» stopwords tiáº¿ng Viá»‡t
    - Tá»‘i Æ°u vector hÃ³a
    - PhÃ¡t hiá»‡n chÃ­nh xÃ¡c hÆ¡n cÃ¡c tin cÃ³ cÃ¹ng ná»™i dung nhÆ°ng khÃ¡c nguá»“n
    """
    if not recent_texts:
        return False
    
    try:
        # Danh sÃ¡ch stopwords tiáº¿ng Viá»‡t cÆ¡ báº£n
        vn_stopwords = {
            "vÃ ", "lÃ ", "cá»§a", "cÃ³", "Ä‘Æ°á»£c", "trong", "cho", "khÃ´ng", "Ä‘Ã£", "vá»›i", "Ä‘Æ°á»£c", "nÃ y",
            "Ä‘áº¿n", "tá»«", "khi", "nhÆ°", "ngÆ°á»i", "nhá»¯ng", "sáº½", "vÃ o", "vá»", "cÃ²n", "bá»‹", "theo",
            "Ä‘á»ƒ", "táº¡i", "nhÆ°ng", "ra", "nÃªn", "má»™t", "cÃ¡c", "cÅ©ng", "Ä‘ang", "tá»›i", "trÃªn", "tÃ´i",
            "báº¡n", "chÃºng", "ráº±ng", "thÃ¬", "Ä‘Ã³", "lÃ m", "náº¿u", "nÃ³i", "bá»Ÿi", "lÃªn", "khÃ¡c", "há»"
        }
        
        # ThÃªm tin má»›i vÃ o Ä‘áº§u danh sÃ¡ch Ä‘á»ƒ vector hÃ³a
        texts = [new_text] + recent_texts
        
        # Tiá»n xá»­ lÃ½ Ä‘á»ƒ loáº¡i bá» nhiá»…u vÃ  giá»¯ láº¡i ná»™i dung quan trá»ng
        # ÄÃ¢y lÃ  bÆ°á»›c quan trá»ng Ä‘á»ƒ phÃ¡t hiá»‡n tin cÃ¹ng ná»™i dung tá»« cÃ¡c nguá»“n khÃ¡c nhau
        processed_texts = []
        for text in texts:
            # Chuáº©n hÃ³a tin, chá»‰ giá»¯ tá»« khÃ³a chÃ­nh
            words = text.lower().split()
            words = [w for w in words if w not in vn_stopwords and len(w) > 1]
            processed_texts.append(' '.join(words))
        
        # TÃ­nh vector TF-IDF, dÃ¹ng ngram tá»« 1-3 Ä‘á»ƒ báº¯t Ä‘Æ°á»£c cá»¥m tá»« cÃ³ Ã½ nghÄ©a
        vectorizer = TfidfVectorizer(
            lowercase=True,
            stop_words="english", # Váº«n giá»¯ cho cÃ¡c tá»« tiáº¿ng Anh
            ngram_range=(1, 3),   # NÃ¢ng lÃªn (1, 3) Ä‘á»ƒ báº¯t cá»¥m tá»« dÃ i hÆ¡n
            min_df=1,
            max_features=10000    # Giá»›i háº¡n sá»‘ lÆ°á»£ng Ä‘áº·c trÆ°ng Ä‘á»ƒ tÄƒng hiá»‡u suáº¥t
        ).fit_transform(processed_texts)
        
        # Chuyá»ƒn sang máº£ng Ä‘á»ƒ so sÃ¡nh
        vectors = vectorizer.toarray()
        
        # TÃ­nh cosine similarity giá»¯a tin má»›i vÃ  cÃ¡c tin cÅ©
        sim_scores = cosine_similarity([vectors[0]], vectors[1:])[0]
        
        # Kiá»ƒm tra cÃ³ trÃ¹ng láº·p khÃ´ng (similarity > threshold)
        max_similarity = max(sim_scores) if len(sim_scores) > 0 else 0
        is_duplicate = max_similarity > threshold
        
        if is_duplicate:
            max_idx = sim_scores.argmax() if len(sim_scores) > 0 else -1
            similar_text = recent_texts[max_idx] if max_idx >= 0 else "N/A"
            logger.info(f"PhÃ¡t hiá»‡n tin trÃ¹ng láº·p! Similarity: {max_similarity:.2f}, Threshold: {threshold}")
            logger.debug(f"Tin má»›i: {new_text[:50]}... | Tin trÃ¹ng: {similar_text[:50]}...")
        
        return is_duplicate
    except Exception as e:
        logger.error(f"Lá»—i khi phÃ¡t hiá»‡n tin trÃ¹ng láº·p: {e}")
        return False  # Náº¿u lá»—i, coi nhÆ° khÃ´ng trÃ¹ng Ä‘á»ƒ xá»­ lÃ½ tin

async def init_redis():
    """Initialize Redis connection"""
    global redis_client
    try:
        redis_client = aioredis.from_url(Config.REDIS_URL)
        
        # Load additional keywords from Redis if they exist
        global additional_keywords
        keywords_data = await redis_client.get("additional_keywords")
        if keywords_data:
            additional_keywords = pickle.loads(keywords_data)
            logger.info(f"Loaded {len(additional_keywords)} additional keywords from Redis")
        
        # Load duplicate detection settings
        dup_threshold = await redis_client.get("duplicate_threshold")
        if dup_threshold:
            try:
                Config.DUPLICATE_THRESHOLD = float(dup_threshold.decode())
                logger.info(f"Loaded duplicate threshold: {Config.DUPLICATE_THRESHOLD}")
            except (ValueError, AttributeError) as e:
                logger.warning(f"Failed to load duplicate threshold: {e}")
                
        title_threshold = await redis_client.get("title_threshold")
        if title_threshold:
            try:
                Config.TITLE_SIMILARITY_THRESHOLD = float(title_threshold.decode())
                logger.info(f"Loaded title similarity threshold: {Config.TITLE_SIMILARITY_THRESHOLD}")
            except (ValueError, AttributeError) as e:
                logger.warning(f"Failed to load title threshold: {e}")
                
        log_similarity = await redis_client.get("log_similarity_details")
        if log_similarity:
            try:
                Config.LOG_SIMILARITY_DETAILS = log_similarity.decode().lower() == "true"
                logger.info(f"Loaded similarity logging setting: {Config.LOG_SIMILARITY_DETAILS}")
            except AttributeError as e:
                logger.warning(f"Failed to load similarity logging setting: {e}")
        
        logger.info("Redis initialized successfully")
        return True
    except Exception as e:
        logger.error(f"Error initializing Redis: {e}")
        return False

async def clear_news_queues():
    """XÃ³a táº¥t cáº£ tin tá»©c trong queue khi khá»Ÿi Ä‘á»™ng láº¡i bot Ä‘á»ƒ trÃ¡nh gá»­i láº¡i tin cÅ©"""
    try:
        # XÃ³a cÃ¡c queue tin tá»©c
        await redis_client.delete("hot_news_queue")
        await redis_client.delete("news_queue")
        # Giá»¯ láº¡i ids Ä‘Ã£ gá»­i Ä‘á»ƒ trÃ¡nh trÃ¹ng láº·p
        logger.info("ÄÃ£ xÃ³a táº¥t cáº£ tin trong queue Ä‘á»ƒ chuáº©n bá»‹ cho quÃ©t má»›i")
    except Exception as e:
        logger.error(f"Lá»—i khi xÃ³a queue tin tá»©c: {e}")

# --- Helper for rotating RSS feed index ---
async def get_current_feed_index():
    idx = await redis_client.get("current_feed_index")
    if idx is not None:
        return int(idx)
    return 0

async def set_current_feed_index(idx):
    await redis_client.set("current_feed_index", str(idx))

# --- Main Function ---

# Global application variable to store our bot instance
application = None

async def send_message_to_user(user_id, message, entry=None, is_hot_news=False):
    """Send a news message to a user"""
    try:
        # Chuáº©n bá»‹ ná»™i dung tin nháº¯n
        title = getattr(entry, 'title', 'KhÃ´ng cÃ³ tiÃªu Ä‘á»')
        link = getattr(entry, 'link', '#')
        # Láº¥y published date vá»›i xá»­ lÃ½ timezone
        published = getattr(entry, 'published', None)
        # Náº¿u published lÃ  string, convert sang datetime
        if isinstance(published, str):
            try:
                published = datetime.datetime.strptime(published, '%a, %d %b %Y %H:%M:%S %Z')
                # Äáº£m báº£o published cÃ³ timezone
                published = ensure_timezone_aware(published)
            except ValueError:
                try:
                    # Thá»­ vá»›i format khÃ¡c (RSS feeds cÃ³ thá»ƒ khÃ¡c nhau)
                    published = datetime.datetime.strptime(published, '%a, %d %b %Y %H:%M:%S %z')
                except ValueError:
                    # Fallback náº¿u parse tháº¥t báº¡i
                    published = None
        # Format date
        date = format_datetime(published) if published else format_datetime(None)
        # Extract domain from link
        domain = urlparse(link).netloc
        # Create message with emoji based on news type
        prefix = "ğŸ”¥ TIN NÃ“NG: " if is_hot_news else "ğŸ“° TIN Má»šI: "
        # Format message
        formatted_message = (
            f"{prefix}<b>{title}</b>\n\n"
            f"<pre>{message}</pre>\n\n"
            f"<i>Nguá»“n: {domain} â€¢ {date}</i>\n"
            f"<a href='{link}'>Äá»c chi tiáº¿t</a>"
        )
        # Táº¡o nÃºt Ä‘á»c chi tiáº¿t
        keyboard = [[InlineKeyboardButton("Äá»c chi tiáº¿t", url=link)]]
        reply_markup = InlineKeyboardMarkup(keyboard)
        # Get the global application's bot
        global application
        if application and application.bot:
            bot = application.bot
        else:
            from telegram import Bot
            bot = Bot(token=Config.BOT_TOKEN)
        # LuÃ´n gá»­i tin nháº¯n text, khÃ´ng gá»­i áº£nh
        await bot.send_message(
            chat_id=user_id,
            text=formatted_message,
            reply_markup=reply_markup,
            parse_mode='HTML',
            disable_web_page_preview=False
        )
    except Exception as e:
        logger.error(f"Lá»—i khi gá»­i tin tá»©c cho user {user_id}: {e}")

# --- CÃ¡c job Ä‘á»‹nh ká»³ má»›i ---

async def fetch_and_cache_news(context: ContextTypes.DEFAULT_TYPE):
    """
    Job cháº¡y má»—i 10 phÃºt Ä‘á»ƒ quÃ©t 1 RSS, lá»c tin vÃ  Ä‘áº©y vÃ o queue (luÃ¢n phiÃªn tá»«ng nguá»“n).
    NÃ¢ng cáº¥p: chá»‰ láº¥y tin trong ngÃ y, lá»c trÃ¹ng tiÃªu Ä‘á» Ä‘Ã£ gá»­i, chuáº©n hÃ³a ná»™i dung khi so sÃ¡nh trÃ¹ng láº·p, 
    lá»c hash ná»™i dung, lá»c tiÃªu Ä‘á» tÆ°Æ¡ng tá»±, lá»c ná»™i dung tÆ°Æ¡ng tá»± tá»« cÃ¡c nguá»“n khÃ¡c nhau.
    """
    try:
        logger.info("Äang quÃ©t 1 RSS vÃ  cache tin má»›i...")
        recent_news_texts_raw = await get_recent_news_texts()
        recent_news_texts = [normalize_text(txt) for txt in recent_news_texts_raw]
        # Láº¥y danh sÃ¡ch tiÃªu Ä‘á» chuáº©n hÃ³a gáº§n Ä‘Ã¢y (giá»›i háº¡n 200)
        recent_titles = await get_recent_titles(limit=200)
        queued_count = 0
        skipped_count = 0
        duplicate_content_count = 0
        hot_news_count = 0
        feeds = Config.FEED_URLS
        feed_idx = await get_current_feed_index()
        feed_url = feeds[feed_idx % len(feeds)]
        logger.info(f"QuÃ©t RSS: {feed_url}")
        entries = await parse_feed(feed_url)
        for entry in entries:
            try:
                if not is_recent_news(entry, days=Config.FETCH_LIMIT_DAYS):
                    continue
                if not is_relevant_news_smart(entry):
                    continue
                entry_id = getattr(entry, 'id', '') or getattr(entry, 'link', '')
                normalized_title = await normalize_title(getattr(entry, 'title', ''))
                
                # 1. Lá»c hash ná»™i dung
                entry_text = f"{getattr(entry, 'title', '')} {getattr(entry, 'summary', '')}"
                entry_text_norm = normalize_text(entry_text)
                content_hash = hashlib.sha256(entry_text_norm.encode('utf-8')).hexdigest()
                if await is_hash_sent(content_hash):
                    skipped_count += 1
                    continue
                    
                # 2. Lá»c tiÃªu Ä‘á» tÆ°Æ¡ng tá»±
                if is_similar_title(normalized_title, recent_titles, threshold=Config.TITLE_SIMILARITY_THRESHOLD):
                    skipped_count += 1
                    continue
                
                # 3. NÃ¢ng cáº¥p: Lá»c tin cÃ³ ná»™i dung tÆ°Æ¡ng tá»± tá»« cÃ¡c nguá»“n khÃ¡c nhau
                # Chuáº©n bá»‹ ná»™i dung Ä‘á»ƒ so sÃ¡nh
                prepared_content = normalize_text(f"{getattr(entry, 'title', '')} {getattr(entry, 'summary', '')}")
                if is_duplicate_by_content(prepared_content, recent_news_texts, threshold=Config.DUPLICATE_THRESHOLD):
                    logger.info(f"PhÃ¡t hiá»‡n tin trÃ¹ng láº·p ná»™i dung tá»« nguá»“n khÃ¡c nhau: {getattr(entry, 'title', '')[:50]}...")
                    duplicate_content_count += 1
                    continue
                
                recent_titles.append(normalized_title)
                
                # 4. Lá»c tiÃªu Ä‘á» Ä‘Ã£ gá»­i tuyá»‡t Ä‘á»‘i
                if await is_title_sent(normalized_title):
                    skipped_count += 1
                    continue
                if await redis_client.sismember("news_queue_ids", entry_id):
                    skipped_count += 1
                    continue
                if await is_sent(entry_id):
                    skipped_count += 1
                    continue
                
                # ThÃªm vÃ o danh sÃ¡ch cÃ¡c ná»™i dung tin gáº§n Ä‘Ã¢y Ä‘á»ƒ so sÃ¡nh cho tin sau
                recent_news_texts.append(entry_text_norm)
                
                # XÃ¡c Ä‘á»‹nh loáº¡i tin & lÆ°u vÃ o queue
                is_hot = is_hot_news_simple(entry)
                news_data = {
                    "id": entry_id,
                    "title": getattr(entry, "title", ""),
                    "link": getattr(entry, "link", ""),
                    "summary": getattr(entry, "summary", ""),
                    "published": getattr(entry, "published", ""),
                    "is_hot": is_hot,
                }
                if is_hot:
                    await redis_client.rpush("hot_news_queue", json.dumps(news_data))
                    hot_news_count += 1
                else:
                    await redis_client.rpush("news_queue", json.dumps(news_data))
                await redis_client.sadd("news_queue_ids", entry_id)
                await redis_client.expire("news_queue_ids", Config.REDIS_TTL)
                await mark_title_sent(normalized_title)
                await mark_hash_sent(content_hash)
                queued_count += 1
                await add_recent_title(normalized_title)
                await add_recent_news_text(entry_text_norm)
            except Exception as e:
                logger.warning(f"Lá»—i khi xá»­ lÃ½ tin tá»« feed {feed_url}: {e}")
        hot_queue_len = await redis_client.llen("hot_news_queue")
        normal_queue_len = await redis_client.llen("news_queue")
        logger.info(f"QuÃ©t RSS hoÃ n táº¥t: ÄÃ£ cache {queued_count} tin má»›i ({hot_news_count} tin nÃ³ng), "
                   f"bá» qua {skipped_count} tin trÃ¹ng láº·p thÃ´ng thÆ°á»ng, {duplicate_content_count} tin trÃ¹ng ná»™i dung. "
                   f"Sá»‘ tin trong queue: {hot_queue_len} tin nÃ³ng, {normal_queue_len} tin thÆ°á»ng.")
        if queued_count == 0:
            logger.info("KhÃ´ng cÃ³ tin má»›i, chuyá»ƒn sang feed tiáº¿p theo vÃ  sáº½ thá»­ sau 1 phÃºt.")
            await set_current_feed_index((feed_idx + 1) % len(feeds))
            context.job_queue.run_once(fetch_and_cache_news, 60)
        else:
            await set_current_feed_index((feed_idx + 1) % len(feeds))
    except Exception as e:
        logger.error(f"Lá»—i trong job fetch_and_cache_news: {e}")

async def send_news_from_queue(context: ContextTypes.DEFAULT_TYPE):
    """
    Job cháº¡y má»—i 800s Ä‘á»ƒ láº¥y 1 tin tá»« queue vÃ  gá»­i cho user.
    Æ¯u tiÃªn tin nÃ³ng trÆ°á»›c.
    """
    try:
        # Láº¥y danh sÃ¡ch ngÆ°á»i dÃ¹ng Ä‘Ã£ Ä‘Æ°á»£c phÃª duyá»‡t
        approved_users_list = [int(uid) for uid in await redis_client.smembers("approved_users")]
        if Config.ADMIN_ID not in approved_users_list:
            approved_users_list.append(Config.ADMIN_ID)
        if not approved_users_list:
            logger.warning("KhÃ´ng cÃ³ ngÆ°á»i dÃ¹ng nÃ o Ä‘Æ°á»£c phÃª duyá»‡t Ä‘á»ƒ gá»­i tin.")
            return
            
        # Æ¯u tiÃªn láº¥y tin nÃ³ng trÆ°á»›c
        news_json = await redis_client.lpop("hot_news_queue")
        if not news_json:
            # Náº¿u khÃ´ng cÃ³ tin nÃ³ng, láº¥y tin thÆ°á»ng
            news_json = await redis_client.lpop("news_queue")
            
        if not news_json:
            logger.info("KhÃ´ng cÃ²n tin trong cáº£ hai queue. Äá»£i chu ká»³ fetch tiáº¿p theo.")
            return
            
        # Parse JSON thÃ nh dict
        news_data = json.loads(news_json)
        
        # PhÃ¢n tÃ­ch tin tá»©c báº±ng AI
        domain = urlparse(news_data['link']).netloc if 'link' in news_data else 'N/A'
        prompt = f"""
        TÃ³m táº¯t vÃ  phÃ¢n tÃ­ch tin tá»©c sau cho nhÃ  Ä‘áº§u tÆ° chá»©ng khoÃ¡n Viá»‡t Nam.
        \nTiÃªu Ä‘á»: {news_data.get('title', 'KhÃ´ng cÃ³ tiÃªu Ä‘á»')}
        TÃ³m táº¯t: {news_data.get('summary', 'KhÃ´ng cÃ³ tÃ³m táº¯t')}
        Nguá»“n: {domain}
        \n1. TÃ³m táº¯t ngáº¯n gá»n ná»™i dung 
        2. ÄÃ¡nh giÃ¡ tÃ¡c Ä‘á»™ng ( 2-3 cÃ¢u ). Cáº£m xÃºc (TÃ­ch cá»±c/TiÃªu cá»±c/Trung láº­p)
	3. MÃ£/ngÃ nh liÃªn quan
        """
        
        try:
            ai_summary = await analyze_news(prompt)
        except Exception as e:
            logger.error(f"Lá»—i khi phÃ¢n tÃ­ch tin báº±ng AI: {e}")
            # Náº¿u khÃ´ng phÃ¢n tÃ­ch Ä‘Æ°á»£c, dÃ¹ng summary gá»‘c
            ai_summary = news_data.get('summary', 'KhÃ´ng cÃ³ phÃ¢n tÃ­ch nÃ o.')
            
        # Táº¡o Ä‘á»‘i tÆ°á»£ng entry tá»« news_data Ä‘á»ƒ truyá»n vÃ o hÃ m gá»­i
        class EntryObject:
            pass
            
        entry = EntryObject()
        for key, value in news_data.items():
            setattr(entry, key, value)
            
        # Xá»­ lÃ½ sentiment náº¿u cáº§n
        is_hot = news_data.get('is_hot', False)
        sentiment = await extract_sentiment(ai_summary) if is_hot else 'Trung láº­p'
            
        # ÄÃ¡nh dáº¥u tin Ä‘Ã£ Ä‘Æ°á»£c gá»­i
        await mark_sent(news_data.get('id', '') or news_data.get('link', ''))
            
        # Gá»­i tin cho táº¥t cáº£ ngÆ°á»i dÃ¹ng
        sent_count = 0
        for user_id in approved_users_list:
            try:
                await send_message_to_user(user_id, ai_summary, entry, news_data.get('is_hot', False))
                sent_count += 1
            except Exception as e:
                logger.error(f"Lá»—i khi gá»­i tin cho user {user_id}: {e}")
                
        logger.info(f"ÄÃ£ gá»­i tin '{news_data.get('title', '')[:30]}...' cho {sent_count}/{len(approved_users_list)} ngÆ°á»i dÃ¹ng.")
        
    except Exception as e:
        logger.error(f"Lá»—i trong job send_news_from_queue: {e}")

# Function to handle callback queries
async def button_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    
    # Handle different callback data
    if query.data == "view_keywords":
        # Reuse view_keywords_command logic
        user_id = update.effective_user.id
        
        if not await is_user_approved(user_id):
            await query.message.reply_text(
                "âŒ Báº¡n chÆ°a Ä‘Æ°á»£c phÃª duyá»‡t Ä‘á»ƒ sá»­ dá»¥ng bot. GÃµ /register Ä‘á»ƒ Ä‘Äƒng kÃ½."
            )
            return
        
        global additional_keywords
        default_keywords = Config.RELEVANT_KEYWORDS
        
        message = (
            f"ğŸ“‹ *Danh sÃ¡ch tá»« khÃ³a hiá»‡n táº¡i*\n\n"
            f"*Tá»« khÃ³a máº·c Ä‘á»‹nh ({len(default_keywords)})*: Bao gá»“m cÃ¡c tá»« khÃ³a vá» chá»©ng khoÃ¡n, kinh táº¿, tÃ i chÃ­nh...\n\n"
        )
        
        if additional_keywords:
            message += f"*Tá»« khÃ³a bá»• sung ({len(additional_keywords)})*:\n{', '.join(additional_keywords)}\n\n"
        else:
            message += "*Tá»« khÃ³a bá»• sung*: ChÆ°a cÃ³\n\n"
        
        message += (
            "Sá»­ dá»¥ng /set_keywords Ä‘á»ƒ thÃªm tá»« khÃ³a bá»• sung.\n"
            "Sá»­ dá»¥ng /clear_keywords Ä‘á»ƒ xÃ³a táº¥t cáº£ tá»« khÃ³a bá»• sung."
        )
        
        await query.message.reply_text(message, parse_mode='Markdown')
    
    elif query.data == "help":
        # Show help message
        await help_command(update, context)
    
    # Handle other callbacks
    elif query.data.startswith("approve_") or query.data.startswith("deny_"):
        await approve_user_callback(update, context)

async def job_ping(context: ContextTypes.DEFAULT_TYPE):
    try:
        url = "https://anvt.onrender.com/health"  # Náº¿u endpoint nÃ y khÃ´ng cÃ³, Ä‘á»•i thÃ nh "/"
        async with httpx.AsyncClient(timeout=10) as client:
            await client.get(url)
        logger.info(f"Ping giá»¯ bot awake tá»›i {url}")
    except Exception as e:
        logger.error(f"Lá»—i khi ping giá»¯ awake: {e}")

async def start_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user = update.effective_user
    await update.message.reply_text(
        f"ğŸ‘‹ Xin chÃ o {user.first_name or 'báº¡n'}! ÄÃ¢y lÃ  bot tá»•ng há»£p tin tá»©c chá»©ng khoÃ¡n, kinh táº¿, tÃ i chÃ­nh.\n"
        "GÃµ /help Ä‘á»ƒ xem hÆ°á»›ng dáº«n sá»­ dá»¥ng."
    )

async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    is_admin = user_id == Config.ADMIN_ID
    
    basic_commands = (
        "CÃ¡c lá»‡nh há»— trá»£:\n"
        "/start - Báº¯t Ä‘áº§u\n"
        "/help - HÆ°á»›ng dáº«n\n"
        "/register - ÄÄƒng kÃ½ sá»­ dá»¥ng bot\n"
        "/keywords - Xem tá»« khÃ³a lá»c tin\n"
        "/set_keywords - ThÃªm tá»« khÃ³a lá»c tin\n"
        "/clear_keywords - XÃ³a tá»« khÃ³a bá»• sung"
    )
    
    if is_admin:
        admin_commands = (
            "\n\nLá»‡nh dÃ nh riÃªng cho admin:\n"
            "/check_dup_settings - Kiá»ƒm tra cÃ i Ä‘áº·t lá»c tin trÃ¹ng\n"
            "/set_dup_threshold - Äiá»u chá»‰nh ngÆ°á»¡ng phÃ¡t hiá»‡n ná»™i dung trÃ¹ng\n"
            "/set_title_threshold - Äiá»u chá»‰nh ngÆ°á»¡ng phÃ¡t hiá»‡n tiÃªu Ä‘á» tÆ°Æ¡ng tá»±\n"
            "/toggle_sim_log - Báº­t/táº¯t log chi tiáº¿t vá» similarity"
        )
        await update.message.reply_text(basic_commands + admin_commands)
    else:
        await update.message.reply_text(basic_commands)

async def view_keywords_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    if not await is_user_approved(user_id):
        await update.message.reply_text(
            "âŒ Báº¡n chÆ°a Ä‘Æ°á»£c phÃª duyá»‡t Ä‘á»ƒ sá»­ dá»¥ng bot. GÃµ /register Ä‘á»ƒ Ä‘Äƒng kÃ½."
        )
        return

    global additional_keywords
    default_keywords = Config.RELEVANT_KEYWORDS

    message = (
        f"ğŸ“‹ *Danh sÃ¡ch tá»« khÃ³a hiá»‡n táº¡i*\n\n"
        f"*Tá»« khÃ³a máº·c Ä‘á»‹nh ({len(default_keywords)})*: Bao gá»“m cÃ¡c tá»« khÃ³a vá» chá»©ng khoÃ¡n, kinh táº¿, tÃ i chÃ­nh...\n\n"
    )

    if additional_keywords:
        message += f"*Tá»« khÃ³a bá»• sung ({len(additional_keywords)})*:\n{', '.join(additional_keywords)}\n\n"
    else:
        message += "*Tá»« khÃ³a bá»• sung*: ChÆ°a cÃ³\n\n"

    message += (
        "Sá»­ dá»¥ng /set_keywords Ä‘á»ƒ thÃªm tá»« khÃ³a bá»• sung.\n"
        "Sá»­ dá»¥ng /clear_keywords Ä‘á»ƒ xÃ³a táº¥t cáº£ tá»« khÃ³a bá»• sung."
    )

    await update.message.reply_text(message, parse_mode='Markdown')

async def set_keywords_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    if not await is_user_approved(user_id):
        await update.message.reply_text(
            "âŒ Báº¡n chÆ°a Ä‘Æ°á»£c phÃª duyá»‡t Ä‘á»ƒ sá»­ dá»¥ng bot. GÃµ /register Ä‘á»ƒ Ä‘Äƒng kÃ½."
        )
        return

    global additional_keywords
    if not context.args:
        await update.message.reply_text(
            "âœï¸ Vui lÃ²ng nháº­p tá»« khÃ³a báº¡n muá»‘n thÃªm. VÃ­ dá»¥: `/set_keywords bitcoin, eth`"
        )
        return

    new_keywords = [normalize_text(kw.strip()) for kw in ' '.join(context.args).split(',') if kw.strip()]
    
    if not new_keywords:
        await update.message.reply_text("âš ï¸ KhÃ´ng cÃ³ tá»« khÃ³a há»£p lá»‡ nÃ o Ä‘Æ°á»£c cung cáº¥p.")
        return

    added_count = 0
    for kw in new_keywords:
        if kw not in additional_keywords:
            additional_keywords.append(kw)
            added_count += 1
    
    if added_count > 0:
        # Save to Redis
        await redis_client.set("additional_keywords", pickle.dumps(additional_keywords))
        await update.message.reply_text(
            f"âœ… ÄÃ£ thÃªm {added_count} tá»« khÃ³a má»›i. Hiá»‡n cÃ³ {len(additional_keywords)} tá»« khÃ³a bá»• sung.\n"
            "GÃµ /keywords Ä‘á»ƒ xem danh sÃ¡ch Ä‘áº§y Ä‘á»§."
        )
    else:
        await update.message.reply_text(
            "â„¹ï¸ CÃ¡c tá»« khÃ³a báº¡n nháº­p Ä‘Ã£ cÃ³ sáºµn hoáº·c khÃ´ng há»£p lá»‡."
        )

async def clear_keywords_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    if not await is_user_approved(user_id):
        await update.message.reply_text(
            "âŒ Báº¡n chÆ°a Ä‘Æ°á»£c phÃª duyá»‡t Ä‘á»ƒ sá»­ dá»¥ng bot. GÃµ /register Ä‘á»ƒ Ä‘Äƒng kÃ½."
        )
        return

    global additional_keywords
    if not additional_keywords:
        await update.message.reply_text("â„¹ï¸ Hiá»‡n khÃ´ng cÃ³ tá»« khÃ³a bá»• sung nÃ o Ä‘á»ƒ xÃ³a.")
        return
        
    additional_keywords.clear()
    # Save to Redis
    await redis_client.delete("additional_keywords")
    await update.message.reply_text(
        "ğŸ—‘ï¸ ÄÃ£ xÃ³a táº¥t cáº£ tá»« khÃ³a bá»• sung. Bot sáº½ chá»‰ sá»­ dá»¥ng danh sÃ¡ch tá»« khÃ³a máº·c Ä‘á»‹nh.\n"
        "GÃµ /keywords Ä‘á»ƒ xem láº¡i."
    )

@admin_only
async def set_duplicate_threshold(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """
    Admin command to set the duplicate detection threshold without restarting the bot
    Usage: /set_dup_threshold 0.65
    """
    if not context.args or len(context.args) != 1:
        await update.message.reply_text(
            "âŒ CÃº phÃ¡p sai. Sá»­ dá»¥ng: `/set_dup_threshold 0.65`\n"
            "GiÃ¡ trá»‹ tá»« 0.0 Ä‘áº¿n 1.0, cÃ ng tháº¥p cÃ ng nháº¡y vá»›i viá»‡c phÃ¡t hiá»‡n trÃ¹ng láº·p."
        )
        return
        
    try:
        threshold = float(context.args[0])
        if threshold < 0.0 or threshold > 1.0:
            await update.message.reply_text("âŒ GiÃ¡ trá»‹ pháº£i tá»« 0.0 Ä‘áº¿n 1.0")
            return
            
        # Cáº­p nháº­t giÃ¡ trá»‹ trong Config
        Config.DUPLICATE_THRESHOLD = threshold
        
        # LÆ°u vÃ o Redis Ä‘á»ƒ giá»¯ giÃ¡ trá»‹ khi khá»Ÿi Ä‘á»™ng láº¡i
        await redis_client.set("duplicate_threshold", str(threshold))
        
        await update.message.reply_text(
            f"âœ… ÄÃ£ cáº­p nháº­t ngÆ°á»¡ng phÃ¡t hiá»‡n tin trÃ¹ng láº·p ná»™i dung: {threshold}\n"
            f"Ãp dá»¥ng ngay cho cÃ¡c láº§n quÃ©t RSS tiáº¿p theo."
        )
    except ValueError:
        await update.message.reply_text("âŒ GiÃ¡ trá»‹ khÃ´ng há»£p lá»‡. Vui lÃ²ng nháº­p sá»‘ tá»« 0.0 Ä‘áº¿n 1.0")

@admin_only
async def toggle_similarity_logging(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """
    Admin command to toggle detailed similarity logging
    Usage: /toggle_sim_log
    """
    # Toggle giÃ¡ trá»‹
    Config.LOG_SIMILARITY_DETAILS = not Config.LOG_SIMILARITY_DETAILS
    
    # LÆ°u vÃ o Redis
    await redis_client.set("log_similarity_details", str(Config.LOG_SIMILARITY_DETAILS).lower())
    
    status = "báº­t" if Config.LOG_SIMILARITY_DETAILS else "táº¯t"
    await update.message.reply_text(
        f"âœ… ÄÃ£ {status} ghi log chi tiáº¿t vá» phÃ¡t hiá»‡n tin trÃ¹ng láº·p.\n"
        "Xem log há»‡ thá»‘ng Ä‘á»ƒ theo dÃµi thÃ´ng tin chi tiáº¿t vá» similarity."
    )

@admin_only
async def check_dup_settings(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """
    Admin command to check current duplicate detection settings
    Usage: /check_dup_settings
    """
    settings = (
        f"ğŸ“Š *CÃ i Ä‘áº·t phÃ¡t hiá»‡n tin trÃ¹ng láº·p*\n\n"
        f"â€¢ NgÆ°á»¡ng tin trÃ¹ng ná»™i dung (DUPLICATE_THRESHOLD): {Config.DUPLICATE_THRESHOLD}\n"
        f"â€¢ NgÆ°á»¡ng tiÃªu Ä‘á» tÆ°Æ¡ng tá»± (TITLE_SIMILARITY_THRESHOLD): {Config.TITLE_SIMILARITY_THRESHOLD}\n"
        f"â€¢ Ghi log chi tiáº¿t: {'Báº­t' if Config.LOG_SIMILARITY_DETAILS else 'Táº¯t'}\n\n"
        f"Lá»‡nh Ä‘iá»u chá»‰nh:\n"
        f"â€¢ /set_dup_threshold [0.0-1.0] - Äáº·t ngÆ°á»¡ng phÃ¡t hiá»‡n ná»™i dung trÃ¹ng láº·p\n"
        f"â€¢ /set_title_threshold [0.0-1.0] - Äáº·t ngÆ°á»¡ng phÃ¡t hiá»‡n tiÃªu Ä‘á» tÆ°Æ¡ng tá»±\n"
        f"â€¢ /toggle_sim_log - Báº­t/táº¯t log chi tiáº¿t vá» similarity"
    )
    await update.message.reply_text(settings, parse_mode='Markdown')

@admin_only
async def set_title_threshold(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """
    Admin command to set the title similarity threshold
    Usage: /set_title_threshold 0.92
    """
    if not context.args or len(context.args) != 1:
        await update.message.reply_text(
            "âŒ CÃº phÃ¡p sai. Sá»­ dá»¥ng: `/set_title_threshold 0.92`\n"
            "GiÃ¡ trá»‹ tá»« 0.0 Ä‘áº¿n 1.0, cÃ ng cao cÃ ng yÃªu cáº§u tiÃªu Ä‘á» giá»‘ng nhau má»›i coi lÃ  trÃ¹ng."
        )
        return
        
    try:
        threshold = float(context.args[0])
        if threshold < 0.0 or threshold > 1.0:
            await update.message.reply_text("âŒ GiÃ¡ trá»‹ pháº£i tá»« 0.0 Ä‘áº¿n 1.0")
            return
            
        # Cáº­p nháº­t giÃ¡ trá»‹ trong Config
        Config.TITLE_SIMILARITY_THRESHOLD = threshold
        
        # LÆ°u vÃ o Redis Ä‘á»ƒ giá»¯ giÃ¡ trá»‹ khi khá»Ÿi Ä‘á»™ng láº¡i
        await redis_client.set("title_threshold", str(threshold))
        
        await update.message.reply_text(
            f"âœ… ÄÃ£ cáº­p nháº­t ngÆ°á»¡ng phÃ¡t hiá»‡n tiÃªu Ä‘á» tÆ°Æ¡ng tá»±: {threshold}\n"
            f"Ãp dá»¥ng ngay cho cÃ¡c láº§n quÃ©t RSS tiáº¿p theo."
        )
    except ValueError:
        await update.message.reply_text("âŒ GiÃ¡ trá»‹ khÃ´ng há»£p lá»‡. Vui lÃ²ng nháº­p sá»‘ tá»« 0.0 Ä‘áº¿n 1.0")

def main():
    global application, shutdown_flag
    
    # Reset shutdown flag
    shutdown_flag = False
    
    # Thiáº¿t láº­p signal handlers
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    
    try:
        application = Application.builder().token(Config.BOT_TOKEN).build()

        # Initialize database and Redis
        loop = asyncio.get_event_loop()
        redis_ok = loop.run_until_complete(init_redis())
        
        # Táº£i cÃ i Ä‘áº·t ngÆ°á»¡ng tá»« Redis náº¿u cÃ³
        if redis_ok:
            dup_threshold = loop.run_until_complete(redis_client.get("duplicate_threshold"))
            if dup_threshold:
                try:
                    Config.DUPLICATE_THRESHOLD = float(dup_threshold.decode())
                except (ValueError, AttributeError):
                    pass
                    
            title_threshold = loop.run_until_complete(redis_client.get("title_threshold"))
            if title_threshold:
                try:
                    Config.TITLE_SIMILARITY_THRESHOLD = float(title_threshold.decode())
                except (ValueError, AttributeError):
                    pass
                    
            log_similarity = loop.run_until_complete(redis_client.get("log_similarity_details"))
            if log_similarity:
                try:
                    Config.LOG_SIMILARITY_DETAILS = log_similarity.decode().lower() == "true"
                except (AttributeError):
                    pass
                    
            logger.info(f"CÃ i Ä‘áº·t lá»c tin trÃ¹ng: DUPLICATE_THRESHOLD={Config.DUPLICATE_THRESHOLD}, " 
                      f"TITLE_SIMILARITY_THRESHOLD={Config.TITLE_SIMILARITY_THRESHOLD}, "
                      f"LOG_SIMILARITY_DETAILS={Config.LOG_SIMILARITY_DETAILS}")

        if not redis_ok:
            logger.error("Failed to initialize Redis. Exiting.")
            return

        # XÃ³a queue cÅ© khi khá»Ÿi Ä‘á»™ng láº¡i
        loop.run_until_complete(clear_news_queues())

        # Add command handlers
        application.add_handler(CommandHandler("start", start_command))
        application.add_handler(CommandHandler("help", help_command))
        application.add_handler(CommandHandler("register", register_user))
        application.add_handler(CommandHandler("keywords", view_keywords_command))
        application.add_handler(CommandHandler("set_keywords", set_keywords_command))
        application.add_handler(CommandHandler("clear_keywords", clear_keywords_command))
        
        # ThÃªm lá»‡nh quáº£n lÃ½ cÃ i Ä‘áº·t lá»c tin trÃ¹ng
        application.add_handler(CommandHandler("check_dup_settings", check_dup_settings))
        application.add_handler(CommandHandler("set_dup_threshold", set_duplicate_threshold))
        application.add_handler(CommandHandler("set_title_threshold", set_title_threshold))
        application.add_handler(CommandHandler("toggle_sim_log", toggle_similarity_logging))

        # Add callback query handler
        application.add_handler(CallbackQueryHandler(button_callback))

        # Set up the job queue
        job_queue = application.job_queue
        
        # Cáº¥u hÃ¬nh cÃ¡c job Ä‘á»‹nh ká»³ má»›i:
        # 1. Job quÃ©t RSS má»—i giá» vÃ  cache tin
        job_queue.run_repeating(fetch_and_cache_news, interval=Config.HOURLY_JOB_INTERVAL, first=10)
        
        # 2. Job gá»­i tin tá»« queue má»—i 800s
        job_queue.run_repeating(send_news_from_queue, interval=Config.NEWS_JOB_INTERVAL, first=30)
        
        # 3. Job ping giá»¯ awake má»—i 5 phÃºt
        job_queue.run_repeating(job_ping, interval=300, first=60)
        
        # In thÃ´ng tin job
        logger.info(f"ÄÃ£ thiáº¿t láº­p 3 job Ä‘á»‹nh ká»³:\n"
                    f"- QuÃ©t RSS & cache: {Config.HOURLY_JOB_INTERVAL}s/láº§n\n"
                    f"- Gá»­i tin tá»« queue: {Config.NEWS_JOB_INTERVAL}s/láº§n\n"
                    f"- Ping giá»¯ awake: 300s/láº§n")

        if Config.WEBHOOK_URL:
            webhook_port = int(os.environ.get("PORT", 8443))
            logger.info(f"Starting webhook on port {webhook_port} with URL: {Config.WEBHOOK_URL}")
            application.run_webhook(
                listen="0.0.0.0",
                port=webhook_port,
                url_path=Config.BOT_TOKEN,
                webhook_url=f"{Config.WEBHOOK_URL}/{Config.BOT_TOKEN}"
            )
        else:
            logger.info("Starting bot in polling mode")
            application.run_polling(allowed_updates=Update.ALL_TYPES)
            
    except Exception as e:
        logger.error(f"Lá»—i khÃ´ng xá»­ lÃ½ Ä‘Æ°á»£c trong hÃ m main: {e}")
        # Dá»n dáº¹p tÃ i nguyÃªn khi cÃ³ lá»—i khÃ´ng xá»­ lÃ½ Ä‘Æ°á»£c
        loop = asyncio.get_event_loop()
        if loop.is_running():
            loop.create_task(cleanup_resources())
        else:
            loop.run_until_complete(cleanup_resources())
        sys.exit(1)

if __name__ == "__main__":
    main()
