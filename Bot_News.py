import logging
import os
import asyncio
# Nh√≥m c√°c import th∆∞ vi·ªán b√™n ngo√†i
import feedparser
import httpx
import asyncpg
import redis.asyncio as aioredis
import google.generativeai as genai
# Nh√≥m import telegram
from telegram import Update, InlineKeyboardMarkup, InlineKeyboardButton
from telegram.ext import Application, CommandHandler, CallbackQueryHandler, ContextTypes, MessageHandler, filters
# Nh√≥m c√°c import kh√°c
import re
from urllib.parse import urlparse
import unicodedata
import datetime
import pytz
from typing import Dict, List, Any, Optional
import pickle
from functools import wraps
# Import cho vi·ªác ph√°t hi·ªán tin tr√πng l·∫∑p
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
# Import cho sentiment analysis ti·∫øng Vi·ªát
import numpy as np
import requests
import json

# --- 1. Config & setup ---
class Config:
    BOT_TOKEN = os.getenv("BOT_TOKEN")
    WEBHOOK_URL = os.getenv("WEBHOOK_URL")
    REDIS_URL = os.getenv("REDIS_URL", "redis://localhost")
    DB_URL = os.getenv("DATABASE_URL")
    ADMIN_ID = int(os.getenv("ADMIN_ID", "1225226589"))
    GOOGLE_GEMINI_API_KEY = os.getenv("GOOGLE_GEMINI_API_KEY")
    OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")
    GEMINI_MODEL = os.getenv("GEMINI_MODEL", "gemini-1.5-pro")
    OPENROUTER_FALLBACK_MODEL = os.getenv("OPENROUTER_FALLBACK_MODEL", "deepseek/deepseek-chat-v3-0324:free")
    GROQ_API_KEY = os.getenv("GROQ_API_KEY")
    GROQ_MODEL = os.getenv("GROQ_MODEL", "mixtral-8x7b-32768")
    FEED_URLS = [
        # Google News theo t·ª´ kh√≥a
        "https://news.google.com/rss/search?q=kinh+t%E1%BA%BF&hl=vi&gl=VN&ceid=VN:vi",
        "https://news.google.com/rss/search?q=ch%E1%BB%A9ng+kho%C3%A1n&hl=vi&gl=VN&ceid=VN:vi",
        "https://news.google.com/rss/search?q=v%C4%A9+m%C3%B4&hl=vi&gl=VN&ceid=VN:vi",
        "https://news.google.com/rss/search?q=chi%E1%BA%BFn+tranh&hl=vi&gl=VN&ceid=VN:vi",
        "https://news.google.com/rss/search?q=l%C3%A3i+su%E1%BA%A5t&hl=vi&gl=VN&ceid=VN:vi",
        "https://news.google.com/rss/search?q=fed&hl=vi&gl=VN&ceid=VN:vi",
        "https://news.google.com/rss/search?q=tin+n%C3%B3ng&hl=vi&gl=VN&ceid=VN:vi",
        "https://news.google.com/rss/search?q=%C4%91%E1%BA%A7u+t%C6%B0&hl=vi&gl=VN&ceid=VN:vi",
        "https://news.google.com/rss/search?q=doanh+nghi%E1%BB%87p&hl=vi&gl=VN&ceid=VN:vi",
        # Ch√≠nh tr·ªã th·∫ø gi·ªõi, quan h·ªá qu·ªëc t·∫ø
        "https://news.google.com/rss/search?q=ch%C3%ADnh+tr%E1%BB%8B+th%E1%BA%BF+gi%E1%BB%9Bi&hl=vi&gl=VN&ceid=VN:vi",
        "https://news.google.com/rss/search?q=geopolitics&hl=vi&gl=VN&ceid=VN:vi",
        "https://news.google.com/rss/search?q=world+politics&hl=vi&gl=VN&ceid=VN:vi",
        "https://news.google.com/rss/search?q=international+relations&hl=vi&gl=VN&ceid=VN:vi",
        # Qu·ªëc t·∫ø (Google News search c√°c ngu·ªìn qu·ªëc t·∫ø)
        "https://news.google.com/rss/search?q=site:bloomberg.com+stock+OR+market+OR+finance&hl=vi&gl=VN&ceid=VN:vi",
        "https://news.google.com/rss/search?q=site:ft.com+stock+OR+market+OR+finance&hl=vi&gl=VN&ceid=VN:vi",
    ]
    REDIS_TTL = int(os.getenv("REDIS_TTL", "21600"))  # 6h
    NEWS_JOB_INTERVAL = int(os.getenv("NEWS_JOB_INTERVAL", "900"))
    HOURLY_JOB_INTERVAL = int(os.getenv("HOURLY_JOB_INTERVAL", "600"))  # 10 ph√∫t/l·∫ßn
    FETCH_LIMIT_DAYS = int(os.getenv("FETCH_LIMIT_DAYS", "2"))  # Ch·ªâ l·∫•y tin 2 ng√†y g·∫ßn nh·∫•t 
    DELETE_OLD_NEWS_DAYS = int(os.getenv("DELETE_OLD_NEWS_DAYS", "2"))
    MAX_RETRIES = int(os.getenv("MAX_RETRIES", "3"))  # S·ªë l·∫ßn th·ª≠ l·∫°i khi feed l·ªói
    MAX_NEWS_PER_CYCLE = int(os.getenv("MAX_NEWS_PER_CYCLE", "1"))  # T·ªëi ƒëa 1 tin m·ªói l·∫ßn
    TIMEZONE = pytz.timezone('Asia/Ho_Chi_Minh')  # Timezone chu·∫©n cho Vi·ªát Nam
    DUPLICATE_THRESHOLD = float(os.getenv("DUPLICATE_THRESHOLD", "0.85"))  # Ng∆∞·ª°ng ƒë·ªÉ x√°c ƒë·ªãnh tin tr√πng l·∫∑p
    RECENT_NEWS_DAYS = int(os.getenv("RECENT_NEWS_DAYS", "3"))  # S·ªë ng√†y ƒë·ªÉ l·∫•y tin g·∫ßn ƒë√¢y ƒë·ªÉ so s√°nh
    
    # C·∫•u h√¨nh ph√°t hi·ªán tin n√≥ng
    HOT_NEWS_KEYWORDS = [
        "kh·∫©n c·∫•p", "tin n√≥ng", "breaking", "kh·ªßng ho·∫£ng", "crash", "s·∫≠p", "b√πng n·ªï", 
        "shock", "·∫£nh h∆∞·ªüng l·ªõn", "th·∫£m kh·ªëc", "th·∫£m h·ªça", "market crash", "sell off", 
        "r∆°i m·∫°nh", "tƒÉng m·∫°nh", "gi·∫£m m·∫°nh", "s·ª•p ƒë·ªï", "b·∫•t th∆∞·ªùng", "emergency", 
        "urgent", "alert", "c·∫£nh b√°o", "ƒë·ªôt bi·∫øn", "l·ªãch s·ª≠", "k·ª∑ l·ª•c", "cao nh·∫•t"
    ]
    HOT_NEWS_IMPACT_PHRASES = [
        "t√°c ƒë·ªông m·∫°nh", "·∫£nh h∆∞·ªüng nghi√™m tr·ªçng", "thay ƒë·ªïi l·ªõn", "bi·∫øn ƒë·ªông m·∫°nh",
        "tr·ªçng ƒëi·ªÉm", "quan tr·ªçng", "ƒë√°ng ch√∫ √Ω", "ƒë√°ng lo ng·∫°i", "c·∫ßn l∆∞u √Ω"
    ]
    
    # Danh s√°ch t·ª´ kh√≥a l·ªçc tin t·ª©c li√™n quan (m·ªü r·ªông)
    RELEVANT_KEYWORDS = [
        # Ch√≠nh tr·ªã, vƒ© m√¥, doanh nghi·ªáp, ch·ª©ng kho√°n, chi·∫øn tranh 
        "ch√≠nh tr·ªã", "vƒ© m√¥", "doanh nghi·ªáp", "ch·ª©ng kho√°n", "chi·∫øn tranh", "ch√≠nh s√°ch", "l√£i su·∫•t", "fed",
        "phe", "ƒë·∫£ng", "ch√≠nh ph·ªß", "qu·ªëc h·ªôi", "nh√† n∆∞·ªõc", "b·ªô tr∆∞·ªüng", "th·ªß t∆∞·ªõng", "ch·ªß t·ªãch",
        # Nh√≥m ng√†nh, bluechip, midcap, th·ªã tr∆∞·ªùng
        "bluechip", "midcap", "ng√¢n h√†ng", "b·∫•t ƒë·ªông s·∫£n", "th√©p", "d·∫ßu kh√≠", "c√¥ng ngh·ªá", "b√°n l·∫ª",
        "xu·∫•t kh·∫©u", "ƒëi·ªán", "x√¢y d·ª±ng", "th·ªßy s·∫£n", "d∆∞·ª£c ph·∫©m", "logistics", "v·∫≠n t·∫£i", 
        # C√°c m√£ ch·ª©ng kho√°n, ch·ªâ s·ªë
        "vn30", "hnx", "upcom", "vnindex", "c·ªï phi·∫øu", "th·ªã tr∆∞·ªùng", "t√†i ch√≠nh", "kinh t·∫ø", 
        "gdp", "l·∫°m ph√°t", "t√≠n d·ª•ng", "tr√°i phi·∫øu", "ph√°i sinh", "qu·ªπ etf", 
        # C√°c m√£ bluechip VN30
        "fpt", "vnm", "vcb", "ssi", "msn", "mwg", "vic", "vhm", "hpg", "ctg", "bid", "mbb", "stb",
        "hdb", "bvh", "vpb", "nvl", "pdr", "tcb", "tpb", "bcm", "pnj", "acb", "vib", "plx",
        # C√°c m√£ midcap, c√°c ch·ªâ b√°o kinh t·∫ø
        "vnm", "cpi", "pmi", "m2", "ƒë·∫ßu t∆∞", "gdp", "xu·∫•t kh·∫©u", "nh·∫≠p kh·∫©u", "d·ª± tr·ªØ", "d·ª± b√°o",
        # T·ª´ kh√≥a t√†i ch√≠nh qu·ªëc t·∫ø
        "fed", "ecb", "boj", "pboc", "imf", "world bank", "nasdaq", "dow jones", "s&p", "nikkei",
        "treasury", "usd", "eur", "jpy", "cny", "bitcoin", "crypto", "commodities", "wti", "brent",
        # M√£ c·ªï phi·∫øu n·ªïi b·∫≠t
        "vnd", "ssi", "hpg", "vic", "vhm", "vnm", "mwg", "ctg", "bid", "tcb", "acb", "vib", "stb", "mbb", "shb",
        # T√™n c√¥ng ty l·ªõn
        "vinamilk", "vietcombank", "vietinbank", "masan", "fpt", "hoa phat", "vietjet", "petro vietnam",
        # S·ª± ki·ªán kinh t·∫ø
        "l·∫°m ph√°t", "tƒÉng tr∆∞·ªüng", "gi·∫£m ph√°t", "GDP", "CPI", "PMI", "xu·∫•t kh·∫©u", "nh·∫≠p kh·∫©u", "t√≠n d·ª•ng", "tr√°i phi·∫øu",
        # Thu·∫≠t ng·ªØ th·ªã tr∆∞·ªùng
        "bull", "bear", "breakout", "margin", "room ngo·∫°i", "ETF", "IPO", "ni√™m y·∫øt", "ph√°t h√†nh", "c·ªï t·ª©c", "chia th∆∞·ªüng",
        # S·ª± ki·ªán qu·ªëc t·∫ø
        "fed", "ecb", "boj", "nasdaq", "dow jones", "s&p", "nikkei", "usd", "eur", "jpy", "bitcoin", "crypto",
    ]

# Danh s√°ch t·ª´ kh√≥a b·ªï sung
additional_keywords = []

# Danh s√°ch t·ª´ kh√≥a ƒë·ªÉ lo·∫°i tr·ª´ tin kh√¥ng li√™n quan
EXCLUDE_KEYWORDS = [
    "khuy·∫øn m√£i", "gi·∫£m gi√°", "mua ngay", "tuy·ªÉn d·ª•ng", "s·ª± ki·ªán", "gi·∫£i tr√≠", "th·ªÉ thao", "lifestyle", 
    "du l·ªãch", "·∫©m th·ª±c", "hot deal", "sale off", "qu·∫£ng c√°o", "ƒë·∫∑t h√†ng", "shoppe", "tiki", "lazada"
]

# --- Ki·ªÉm tra bi·∫øn m√¥i tr∆∞·ªùng b·∫Øt bu·ªôc ---
REQUIRED_ENV_VARS = ["BOT_TOKEN", "OPENROUTER_API_KEY"]
for var in REQUIRED_ENV_VARS:
    if not os.getenv(var):
        raise RuntimeError(f"Missing required environment variable: {var}")

# --- Logging ---
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# --- Redis ---
redis_client = None

# --- PostgreSQL ---
pool = None

# L∆∞u tr·ªØ danh s√°ch user ƒë√£ ƒë∆∞·ª£c duy·ªát
approved_users = set()

async def is_sent(entry_id):
    return await redis_client.sismember("sent_news", entry_id)

async def mark_sent(entry_id):
    await redis_client.sadd("sent_news", entry_id)
    await redis_client.expire("sent_news", Config.REDIS_TTL)

async def save_news(entry, ai_summary, sentiment, is_hot_news=False):
    try:
        # L·∫•y th·ªùi gian hi·ªán t·∫°i v·ªõi timezone, lu√¥n ƒë·∫£m b·∫£o timezone
        now = get_now_with_tz()
        now = ensure_timezone_aware(now)  # ƒê·∫£m b·∫£o c√≥ timezone

        # Log debug ƒë·ªÉ tr·ª£ gi√∫p ph√°t hi·ªán l·ªói timezone
        logger.debug(f"L∆∞u tin v√†o DB: timezone={now.tzinfo}, value={now}")

        async with pool.acquire() as conn:
            # D√πng AT TIME ZONE trong PostgreSQL ƒë·ªÉ ƒë·∫£m b·∫£o nh·∫•t qu√°n
            await conn.execute("""
                INSERT INTO news_insights (title, link, summary, sentiment, ai_opinion, is_hot_news, created_at)
                VALUES ($1, $2, $3, $4, $5, $6, $7::timestamptz)
                ON CONFLICT (link) DO NOTHING
            """, entry.title, entry.link, entry.summary, sentiment, ai_summary, is_hot_news, now)
    except Exception as e:
        logging.warning(f"L·ªói khi l∆∞u tin t·ª©c v√†o DB (link={entry.link}): {e}")
        logging.debug(f"Debug datetime: type={type(now)}, tzinfo={now.tzinfo}, value={now}")

async def is_in_db(entry):
    async with pool.acquire() as conn:
        row = await conn.fetchrow("SELECT 1 FROM news_insights WHERE link=$1", entry.link)
        return row is not None

# H√†m x√≥a tin c≈© h∆°n n ng√†y
async def delete_old_news(days=Config.DELETE_OLD_NEWS_DAYS):
    try:
        async with pool.acquire() as conn:
            await conn.execute(
                f"DELETE FROM news_insights WHERE created_at < NOW() - INTERVAL '{days} days'"
            )
            count = await conn.fetchval("SELECT count(*) FROM news_insights")
            logger.info(f"ƒê√£ x√≥a tin c≈© h∆°n {days} ng√†y. C√≤n l·∫°i {count} tin trong DB.")
    except Exception as e:
        logging.error(f"L·ªói khi x√≥a tin c≈©: {e}")

# --- AI Analysis (Gemini) ---
GEMINI_MODEL = Config.GEMINI_MODEL
OPENROUTER_FALLBACK_MODEL = Config.OPENROUTER_FALLBACK_MODEL
GOOGLE_GEMINI_API_KEY = Config.GOOGLE_GEMINI_API_KEY

async def call_groq_api(prompt, model=None):
    """G·ªçi Groq API ƒë·ªÉ l·∫•y k·∫øt qu·∫£ AI ph√¢n t√≠ch"""
    api_key = Config.GROQ_API_KEY
    model = model or Config.GROQ_MODEL
    if not api_key:
        raise RuntimeError("GROQ_API_KEY is not set")
    try:
        async with httpx.AsyncClient(timeout=30) as client:
            response = await client.post(
                "https://api.groq.com/openai/v1/chat/completions",
                headers={
                    "Authorization": f"Bearer {api_key}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": model,
                    "messages": [{"role": "user", "content": prompt}],
                    "temperature": 0.7
                }
            )
            result = response.json()
            if "choices" not in result:
                logging.error(f"Groq API error (model={model}): {result}")
                raise RuntimeError(f"Groq API error: {result}")
            return result["choices"][0]["message"]["content"]
    except Exception as e:
        logging.error(f"Groq API l·ªói: {e}")
        raise e

async def analyze_news(prompt, model=None):
    try:
        # G·ªçi Google Gemini API ch√≠nh th·ª©c
        genai.configure(api_key=GOOGLE_GEMINI_API_KEY)
        model = genai.GenerativeModel("gemini-1.5-pro")
        response = await asyncio.to_thread(model.generate_content, prompt)
        return response.text
    except Exception as e:
        logging.error(f"Gemini API l·ªói: {e}, fallback sang OpenRouter {OPENROUTER_FALLBACK_MODEL}")
        # Fallback sang OpenRouter
        try:
            async with httpx.AsyncClient(timeout=30) as client:
                response = await client.post(
                    "https://openrouter.ai/api/v1/chat/completions",
                    headers={"Authorization": f"Bearer {os.getenv('OPENROUTER_API_KEY')}",},
                    json={
                        "model": OPENROUTER_FALLBACK_MODEL,
                        "messages": [{"role": "user", "content": prompt}],
                        "temperature": 0.7
                    }
                )
                result = response.json()
                if "choices" not in result:
                    logging.error(f"OpenRouter API error (model={OPENROUTER_FALLBACK_MODEL}): {result}")
                    raise RuntimeError(f"OpenRouter API error: {result}")
                return result["choices"][0]["message"]["content"]
        except Exception as e2:
            logging.error(f"OpenRouter fallback c≈©ng l·ªói: {e2}, th·ª≠ ti·∫øp Groq...")
            # Fallback sang Groq
            try:
                return await call_groq_api(prompt)
            except Exception as e3:
                logging.error(f"Groq fallback c≈©ng l·ªói: {e3}")
                raise e3

# --- Extract sentiment from AI result ---
def extract_sentiment_rule_based(ai_summary):
    """Extract sentiment from AI summary using rule-based approach"""
    sentiment = "Trung l·∫≠p"  # Default
    try:
        # T√¨m ki·∫øm d√≤ng c√≥ ch·ª©a 'c·∫£m x√∫c'
        for line in ai_summary.splitlines():
            line_lower = line.lower()
            if "c·∫£m x√∫c:" in line_lower or "sentiment:" in line_lower:
                sentiment_text = line.split(":")[-1].strip().lower()
                if "t√≠ch c·ª±c" in sentiment_text or "positive" in sentiment_text:
                    return "T√≠ch c·ª±c"
                elif "ti√™u c·ª±c" in sentiment_text or "negative" in sentiment_text:
                    return "Ti√™u c·ª±c"
                else:
                    return "Trung l·∫≠p"
        # N·∫øu kh√¥ng t√¨m th·∫•y d√≤ng c·∫£m x√∫c, d√πng regex t√¨m to√†n vƒÉn b·∫£n
        text = ai_summary.lower()
        if re.search(r"(t√≠ch c·ª±c|positive|l·∫°c quan|upbeat|bullish)", text):
            return "T√≠ch c·ª±c"
        elif re.search(r"(ti√™u c·ª±c|negative|bi quan|bearish|lo ng·∫°i|lo l·∫Øng)", text):
            return "Ti√™u c·ª±c"
    except Exception as e:
        logging.warning(f"L·ªói khi parse sentiment rule-based: {e}")
    return sentiment

async def extract_sentiment(ai_summary):
    """Extract sentiment from AI summary, ch·ªâ s·ª≠ d·ª•ng rule-based"""
    return extract_sentiment_rule_based(ai_summary)

def is_hot_news(entry, ai_summary, sentiment):
    """Ph√°t hi·ªán tin n√≥ng d·ª±a tr√™n ph√¢n t√≠ch n·ªôi dung, t·ª´ kh√≥a v√† c·∫£m x√∫c"""
    try:
        title = getattr(entry, 'title', '').lower()
        summary = getattr(entry, 'summary', '').lower()
        content_text = f"{title} {summary}".lower()
        
        # 1. Ki·ªÉm tra t·ª´ kh√≥a tin n√≥ng trong ti√™u ƒë·ªÅ ho·∫∑c n·ªôi dung
        for keyword in Config.HOT_NEWS_KEYWORDS:
            if keyword.lower() in content_text:
                logging.info(f"Hot news ph√°t hi·ªán b·ªüi t·ª´ kh√≥a '{keyword}': {title}")
                return True
                
        # 2. Ki·ªÉm tra c√°c c·ª•m t·ª´ ·∫£nh h∆∞·ªüng trong AI summary
        ai_text = ai_summary.lower()
        for phrase in Config.HOT_NEWS_IMPACT_PHRASES:
            if phrase.lower() in ai_text:
                logging.info(f"Hot news ph√°t hi·ªán b·ªüi c·ª•m t·ª´ ·∫£nh h∆∞·ªüng '{phrase}': {title}")
                return True
        
        # 3. Ph√¢n t√≠ch d·ª±a tr√™n c·∫£m x√∫c v√† m·ª©c ƒë·ªô ·∫£nh h∆∞·ªüng
        if sentiment != "Trung l·∫≠p":
            # N·∫øu c√≥ c·∫£m x√∫c v√† c√°c t·ª´ ch·ªâ m·ª©c ƒë·ªô cao trong ph√¢n t√≠ch AI
            intensity_words = ["r·∫•t", "m·∫°nh", "nghi√™m tr·ªçng", "ƒë√°ng k·ªÉ", "l·ªõn", "quan tr·ªçng"]
            for word in intensity_words:
                if word in ai_text and (
                    "th·ªã tr∆∞·ªùng" in ai_text or "nh√† ƒë·∫ßu t∆∞" in ai_text or "·∫£nh h∆∞·ªüng" in ai_text
                ):
                    logging.info(f"Hot news ph√°t hi·ªán b·ªüi c·∫£m x√∫c v√† m·ª©c ƒë·ªô ·∫£nh h∆∞·ªüng: {title}")
                    return True
        
        return False
    except Exception as e:
        logging.warning(f"L·ªói khi ph√°t hi·ªán tin n√≥ng: {e}")
        return False

# --- Parse RSS Feed & News Processing ---
def normalize_text(text):
    if not text:
        return ""
    # Lo·∫°i b·ªè d·∫•u ti·∫øng Vi·ªát
    text = unicodedata.normalize('NFD', text)
    text = ''.join([c for c in text if unicodedata.category(c) != 'Mn'])
    # Lo·∫°i b·ªè k√Ω t·ª± ƒë·∫∑c bi·ªát, ch·ªâ gi·ªØ l·∫°i ch·ªØ v√† s·ªë
    text = re.sub(r'[^a-zA-Z0-9 ]', '', text)
    # Vi·∫øt th∆∞·ªùng, lo·∫°i b·ªè kho·∫£ng tr·∫Øng th·ª´a
    text = text.lower().strip()
    return text

def is_recent_news(entry, days=Config.FETCH_LIMIT_DAYS):
    """
    Ki·ªÉm tra tin c√≥ n·∫±m trong khung th·ªùi gian days g·∫ßn nh·∫•t kh√¥ng.
    """
    published = getattr(entry, 'published', None) or getattr(entry, 'updated', None)
    if not published:
        return False
    try:
        # Th·ª≠ parse nhi·ªÅu ƒë·ªãnh d·∫°ng ng√†y th√°ng
        try:
            dt = datetime.datetime.strptime(published, '%a, %d %b %Y %H:%M:%S %Z')
        except ValueError:
            try:
                dt = datetime.datetime.strptime(published, '%a, %d %b %Y %H:%M:%S %z')
            except ValueError:
                # Fallback: n·∫øu kh√¥ng parse ƒë∆∞·ª£c, coi nh∆∞ l√† tin m·ªõi
                return True
        
        # ƒê·∫£m b·∫£o c√≥ timezone
        if not dt.tzinfo:
            dt = Config.TIMEZONE.localize(dt)
        now = get_now_with_tz()
        delta = now - dt
        return delta.days < days
    except Exception as e:
        logger.warning(f"L·ªói khi ki·ªÉm tra th·ªùi gian tin: {e}")
        # N·∫øu c√≥ l·ªói, coi nh∆∞ l√† tin m·ªõi ƒë·ªÉ an to√†n
        return True

def is_relevant_news_smart(entry):
    """
    L·ªçc tin th√¥ng minh: nhi·ªÅu t·ª´ kh√≥a li√™n quan, lo·∫°i tr·ª´ spam/PR.
    """
    title = normalize_text(getattr(entry, 'title', ''))
    summary = normalize_text(getattr(entry, 'summary', ''))
    content_text = f"{title} {summary}"

    # Lo·∫°i tr·ª´ tin spam/PR
    for ex_kw in EXCLUDE_KEYWORDS:
        if normalize_text(ex_kw) in content_text:
            return False

    # ƒê·∫øm s·ªë t·ª´ kh√≥a li√™n quan xu·∫•t hi·ªán
    all_keywords = [normalize_text(k) for k in Config.RELEVANT_KEYWORDS] + [normalize_text(k) for k in additional_keywords]
    match_count = sum(1 for kw in all_keywords if kw and kw in content_text)
    
    # Ph·∫£i c√≥ √≠t nh·∫•t 1 t·ª´ kh√≥a
    return match_count >= 1

def is_hot_news_simple(entry):
    """
    Ph√°t hi·ªán tin n√≥ng m√† kh√¥ng d√πng AI, ch·ªâ d·ª±a tr√™n t·ª´ kh√≥a.
    """
    title = getattr(entry, 'title', '').lower()
    summary = getattr(entry, 'summary', '').lower()
    content_text = f"{title} {summary}".lower()
    
    for keyword in Config.HOT_NEWS_KEYWORDS:
        if keyword.lower() in content_text:
            logger.info(f"Hot news ƒë∆°n gi·∫£n ph√°t hi·ªán b·ªüi t·ª´ kh√≥a '{keyword}': {title}")
            return True
    
    return False

def is_relevant_news(entry):
    """
    Ki·ªÉm tra xem tin t·ª©c c√≥ li√™n quan ƒë·∫øn c√°c ch·ªß ƒë·ªÅ quan t√¢m kh√¥ng d·ª±a tr√™n t·ª´ kh√≥a (chu·∫©n h√≥a)
    """
    # L·∫•y n·ªôi dung t·ª´ ti√™u ƒë·ªÅ v√† t√≥m t·∫Øt, chu·∫©n h√≥a
    title = normalize_text(getattr(entry, 'title', ''))
    summary = normalize_text(getattr(entry, 'summary', ''))
    content_text = f"{title} {summary}"

    # Chu·∫©n h√≥a t·ª´ kh√≥a m·∫∑c ƒë·ªãnh v√† b·ªï sung
    all_keywords = [normalize_text(k) for k in Config.RELEVANT_KEYWORDS] + [normalize_text(k) for k in additional_keywords]

    # So kh·ªõp t·ª´ kh√≥a
    for keyword in all_keywords:
        if keyword and keyword in content_text:
            return True
    return False

async def parse_feed(url):
    try:
        feed_data = await asyncio.to_thread(feedparser.parse, url)
        if not feed_data.entries:
            logger.warning(f"Kh√¥ng t√¨m th·∫•y tin t·ª©c t·ª´ feed: {url}")
            return []
        return feed_data.entries
    except Exception as e:
        logger.error(f"L·ªói khi parse RSS feed {url}: {e}")
        return []

def extract_image_url(entry):
    """Extract image URL from entry if available"""
    try:
        if 'media_content' in entry and entry.media_content:
            for media in entry.media_content:
                if 'url' in media:
                    return media['url']
        
        # Try finding image in content
        if 'content' in entry and entry.content:
            for content in entry.content:
                if 'value' in content:
                    match = re.search(r'<img[^>]+src="([^">]+)"', content['value'])
                    if match:
                        return match.group(1)
        
        # Try finding image in summary
        if hasattr(entry, 'summary'):
            match = re.search(r'<img[^>]+src="([^">]+)"', entry.summary)
            if match:
                return match.group(1)
    except Exception as e:
        logger.warning(f"L·ªói khi extract ·∫£nh: {e}")
    
    return None
    
# --- Command Handler Functions ---

# Admin only decorator
def admin_only(func):
    @wraps(func)
    async def wrapped(update: Update, context: ContextTypes.DEFAULT_TYPE, *args, **kwargs):
        user_id = update.effective_user.id
        if user_id != Config.ADMIN_ID:
            await update.message.reply_text("‚ùå B·∫°n kh√¥ng c√≥ quy·ªÅn s·ª≠ d·ª•ng l·ªánh n√†y.")
            return
        return await func(update, context, *args, **kwargs)
    return wrapped

# Registration system - Only approved users can use the bot
async def is_user_approved(user_id):
    """Ki·ªÉm tra xem user ƒë√£ ƒë∆∞·ª£c duy·ªát ch∆∞a"""
    global approved_users
    return user_id == Config.ADMIN_ID or user_id in approved_users

# Registration commands
async def register_user(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user = update.effective_user
    user_id = user.id
    
    # Check if already approved
    if await is_user_approved(user_id):
        await update.message.reply_text("‚úÖ B·∫°n ƒë√£ ƒë∆∞·ª£c ƒëƒÉng k√Ω s·ª≠ d·ª•ng bot r·ªìi!")
        return
    
    # Notify admin about registration request
    keyboard = [
        [
            InlineKeyboardButton("Approve ‚úÖ", callback_data=f"approve_{user_id}"),
            InlineKeyboardButton("Deny ‚ùå", callback_data=f"deny_{user_id}")
        ]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    await context.bot.send_message(
        chat_id=Config.ADMIN_ID,
        text=(
            f"üîî Y√™u c·∫ßu ƒëƒÉng k√Ω m·ªõi:\n"
            f"User ID: {user_id}\n"
            f"Name: {user.first_name} {user.last_name or ''}\n"
            f"Username: @{user.username or 'N/A'}"
        ),
        reply_markup=reply_markup
    )
    
    await update.message.reply_text(
        "üìù Y√™u c·∫ßu ƒëƒÉng k√Ω c·ªßa b·∫°n ƒë√£ ƒë∆∞·ª£c g·ª≠i t·ªõi admin. "
        "B·∫°n s·∫Ω ƒë∆∞·ª£c th√¥ng b√°o khi y√™u c·∫ßu ƒë∆∞·ª£c x·ª≠ l√Ω."
    )

# Callback handler for approve/deny requests
async def approve_user_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    
    action, user_id = query.data.split("_")
    user_id = int(user_id)
    
    if action == "approve":
        # Add to approved users
        global approved_users
        approved_users.add(user_id)
        
        # Save to database
        async with pool.acquire() as conn:
            await conn.execute(
                "INSERT INTO approved_users (user_id) VALUES ($1) ON CONFLICT (user_id) DO NOTHING",
                str(user_id)
            )
        
        await query.edit_message_text(f"‚úÖ User {user_id} ƒë√£ ƒë∆∞·ª£c ph√™ duy·ªát.")
        await context.bot.send_message(
            chat_id=user_id,
            text="‚úÖ B·∫°n ƒë√£ ƒë∆∞·ª£c ph√™ duy·ªát ƒë·ªÉ s·ª≠ d·ª•ng Bot News! G√µ /help ƒë·ªÉ xem h∆∞·ªõng d·∫´n."
        )
    else:
        await query.edit_message_text(f"‚ùå ƒê√£ t·ª´ ch·ªëi y√™u c·∫ßu t·ª´ user {user_id}.")
        await context.bot.send_message(
            chat_id=user_id,
            text="‚ùå Y√™u c·∫ßu s·ª≠ d·ª•ng bot c·ªßa b·∫°n ƒë√£ b·ªã t·ª´ ch·ªëi."
        )

# Start command
async def start_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user = update.effective_user
    user_id = user.id
    
    if not await is_user_approved(user_id):
        await update.message.reply_text(
            "üëã Ch√†o m·ª´ng b·∫°n ƒë·∫øn v·ªõi Bot News Ch·ª©ng Kho√°n!"
            "\n\nƒê·ªÉ s·ª≠ d·ª•ng bot, b·∫°n c·∫ßn ƒëƒÉng k√Ω v√† ƒë∆∞·ª£c ph√™ duy·ªát."
            "\nG√µ /register ƒë·ªÉ g·ª≠i y√™u c·∫ßu ƒëƒÉng k√Ω."
        )
        return
    
    welcome_message = (
        f"üëã Ch√†o m·ª´ng {user.first_name} ƒë·∫øn v·ªõi Bot News Ch·ª©ng Kho√°n!\n\n"
        f"Bot n√†y gi√∫p b·∫°n nh·∫≠n tin t·ª©c ch·ª©ng kho√°n, kinh t·∫ø v√† t√†i ch√≠nh quan tr·ªçng, "
        f"k√®m ph√¢n t√≠ch AI gi√∫p ƒë√°nh gi√° t√°c ƒë·ªông.\n\n"
        f"üîç Tin t·ª©c s·∫Ω ƒë∆∞·ª£c l·ªçc theo t·ª´ kh√≥a quan tr·ªçng v√† g·ª≠i t·ª± ƒë·ªông khi c√≥ tin m·ªõi.\n"
        f"üî• Tin n√≥ng s·∫Ω ƒë∆∞·ª£c g·∫Øn th·∫ª ∆∞u ti√™n cao h∆°n.\n\n"
        f"G√µ /help ƒë·ªÉ xem to√†n b·ªô l·ªánh v√† h∆∞·ªõng d·∫´n s·ª≠ d·ª•ng."
    )
    
    keyboard = [
        [InlineKeyboardButton("üîë Xem t·ª´ kh√≥a hi·ªán t·∫°i", callback_data="view_keywords")],
        [InlineKeyboardButton("‚ùì H·ªó tr·ª£", callback_data="help")]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    await update.message.reply_text(welcome_message, reply_markup=reply_markup)

# Help command
async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    
    # X√°c ƒë·ªãnh xem ng∆∞·ªùi d√πng c√≥ ph·∫£i admin kh√¥ng ƒë·ªÉ hi·ªÉn th·ªã l·ªánh n√¢ng cao
    is_admin = (user_id == Config.ADMIN_ID)
    
    if not await is_user_approved(user_id) and not is_admin:
        await update.message.reply_text(
            "üëã Ch√†o m·ª´ng b·∫°n ƒë·∫øn v·ªõi Bot News Ch·ª©ng Kho√°n!"
            "\n\nƒê·ªÉ s·ª≠ d·ª•ng bot, b·∫°n c·∫ßn ƒëƒÉng k√Ω v√† ƒë∆∞·ª£c ph√™ duy·ªát."
            "\nG√µ /register ƒë·ªÉ g·ª≠i y√™u c·∫ßu ƒëƒÉng k√Ω."
        )
        return
    
    help_text = (
        "üìö *H∆Ø·ªöNG D·∫™N S·ª¨ D·ª§NG BOT NEWS*\n\n"
        "*L·ªánh c∆° b·∫£n:*\n"
        "/start - Kh·ªüi ƒë·ªông bot\n"
        "/help - Hi·ªÉn th·ªã h∆∞·ªõng d·∫´n n√†y\n"
        "/register - ƒêƒÉng k√Ω s·ª≠ d·ª•ng bot\n\n"
        
        "*Qu·∫£n l√Ω t·ª´ kh√≥a:*\n"
        "/keywords - Xem danh s√°ch t·ª´ kh√≥a theo d√µi\n"
        "/set_keywords <t·ª´ kh√≥a> - Th√™m t·ª´ kh√≥a (c√°ch nhau b·ªüi d·∫•u ph·∫©y)\n"
        "/clear_keywords - X√≥a t·∫•t c·∫£ t·ª´ kh√≥a b·ªï sung\n\n"
        
        "*L∆∞u √Ω:*\n"
        "‚Ä¢ Bot s·∫Ω t·ª± ƒë·ªông g·ª≠i tin t·ª©c quan tr·ªçng khi ph√°t hi·ªán\n"
        "‚Ä¢ Tin n√≥ng s·∫Ω ƒë∆∞·ª£c ƒë√°nh d·∫•u ƒë·∫∑c bi·ªát\n"
        "‚Ä¢ M·ªói tin ƒë∆∞·ª£c ph√¢n t√≠ch b·ªüi AI ƒë·ªÉ ƒë√°nh gi√° t√°c ƒë·ªông\n"
    )
    
    # Th√™m l·ªánh admin n·∫øu l√† admin
    if is_admin:
        admin_help = (
            "\n*L·ªánh d√†nh cho Admin:*\n"
            "‚Ä¢ Ng∆∞·ªùi d√πng m·ªõi s·∫Ω g·ª≠i request v√† admin nh·∫≠n th√¥ng b√°o\n"
            "‚Ä¢ Admin c√≥ th·ªÉ ph√™ duy·ªát/t·ª´ ch·ªëi qua n√∫t b·∫•m\n"
        )
        help_text += admin_help
    
    await update.message.reply_text(help_text, parse_mode='Markdown')

# Keyword management commands
async def set_keywords_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    
    if not await is_user_approved(user_id):
        await update.message.reply_text(
            "‚ùå B·∫°n ch∆∞a ƒë∆∞·ª£c ph√™ duy·ªát ƒë·ªÉ s·ª≠ d·ª•ng bot. G√µ /register ƒë·ªÉ ƒëƒÉng k√Ω."
        )
        return
    
    # L·∫•y t·ª´ kh√≥a t·ª´ arguments
    if not context.args or not context.args[0]:
        await update.message.reply_text(
            "‚ùå Vui l√≤ng nh·∫≠p c√°c t·ª´ kh√≥a, c√°ch nhau b·ªüi d·∫•u ph·∫©y.\n"
            "V√≠ d·ª•: /set_keywords bitcoin, AI, tesla, v√†ng"
        )
        return
    
    # X·ª≠ l√Ω t·ª´ kh√≥a
    text = ' '.join(context.args)
    global additional_keywords
    new_keywords = [kw.strip() for kw in text.split(',') if kw.strip()]
    
    if not new_keywords:
        await update.message.reply_text("‚ùå Kh√¥ng t√¨m th·∫•y t·ª´ kh√≥a h·ª£p l·ªá.")
        return
    
    # C·∫≠p nh·∫≠t t·ª´ kh√≥a
    additional_keywords = new_keywords
    
    # L∆∞u v√†o Redis ƒë·ªÉ ghi nh·ªõ
    try:
        await redis_client.set("additional_keywords", pickle.dumps(additional_keywords), ex=86400*30)  # 30 ng√†y
    except Exception as e:
        logger.error(f"L·ªói khi l∆∞u t·ª´ kh√≥a v√†o Redis: {e}")
    
    await update.message.reply_text(
        f"‚úÖ ƒê√£ c·∫≠p nh·∫≠t {len(new_keywords)} t·ª´ kh√≥a b·ªï sung:\n"
        f"{', '.join(new_keywords)}"
    )

async def view_keywords_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    
    if not await is_user_approved(user_id):
        await update.message.reply_text(
            "‚ùå B·∫°n ch∆∞a ƒë∆∞·ª£c ph√™ duy·ªát ƒë·ªÉ s·ª≠ d·ª•ng bot. G√µ /register ƒë·ªÉ ƒëƒÉng k√Ω."
        )
        return
    
    global additional_keywords
    default_keywords = Config.RELEVANT_KEYWORDS
    
    message = (
        f"üìã *Danh s√°ch t·ª´ kh√≥a hi·ªán t·∫°i*\n\n"
        f"*T·ª´ kh√≥a m·∫∑c ƒë·ªãnh ({len(default_keywords)})*: Bao g·ªìm c√°c t·ª´ kh√≥a v·ªÅ ch·ª©ng kho√°n, kinh t·∫ø, t√†i ch√≠nh...\n\n"
    )
    
    if additional_keywords:
        message += f"*T·ª´ kh√≥a b·ªï sung ({len(additional_keywords)})*:\n{', '.join(additional_keywords)}\n\n"
    else:
        message += "*T·ª´ kh√≥a b·ªï sung*: Ch∆∞a c√≥\n\n"
    
    message += (
        "S·ª≠ d·ª•ng /set_keywords ƒë·ªÉ th√™m t·ª´ kh√≥a b·ªï sung.\n"
        "S·ª≠ d·ª•ng /clear_keywords ƒë·ªÉ x√≥a t·∫•t c·∫£ t·ª´ kh√≥a b·ªï sung."
    )
    
    await update.message.reply_text(message, parse_mode='Markdown')

async def clear_keywords_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    
    if not await is_user_approved(user_id):
        await update.message.reply_text(
            "‚ùå B·∫°n ch∆∞a ƒë∆∞·ª£c ph√™ duy·ªát ƒë·ªÉ s·ª≠ d·ª•ng bot. G√µ /register ƒë·ªÉ ƒëƒÉng k√Ω."
        )
        return
    
    global additional_keywords
    additional_keywords = []
    
    # X√≥a kh·ªèi Redis
    try:
        await redis_client.delete("additional_keywords")
    except Exception as e:
        logger.error(f"L·ªói khi x√≥a t·ª´ kh√≥a t·ª´ Redis: {e}")
    
    await update.message.reply_text("‚úÖ ƒê√£ x√≥a t·∫•t c·∫£ t·ª´ kh√≥a b·ªï sung.")

# --- Timezone Helper Functions ---
def get_now_with_tz():
    """Return current datetime with timezone"""
    return datetime.datetime.now(Config.TIMEZONE)

def format_datetime(dt, format='%Y-%m-%d %H:%M:%S'):
    """Format datetime with timezone if needed"""
    if dt is None:
        return get_now_with_tz().strftime(format)
    
    # Check if datetime has timezone info
    if not dt.tzinfo:
        # Add timezone info if missing
        dt = Config.TIMEZONE.localize(dt)
    
    return dt.strftime(format)

def ensure_timezone_aware(dt):
    """ƒê·∫£m b·∫£o datetime object c√≥ timezone tr∆∞·ªõc khi ƒë∆∞a v√†o DB"""
    if dt is None:
        return get_now_with_tz()
    # N·∫øu ƒë√£ c√≥ tzinfo v√† offset, tr·∫£ v·ªÅ nguy√™n b·∫£n
    if dt.tzinfo is not None and dt.tzinfo.utcoffset(dt) is not None:
        return dt
    # N·∫øu ch∆∞a c√≥ timezone, th√™m v√†o
    try:
        return Config.TIMEZONE.localize(dt)
    except (ValueError, AttributeError):
        # X·ª≠ l√Ω c√°c tr∆∞·ªùng h·ª£p ngo·∫°i l·ªá
        logger.warning(f"Kh√¥ng th·ªÉ th√™m timezone cho datetime: {dt}")
        # T·∫°o m·ªõi datetime v·ªõi timezone
        return datetime.datetime(
            dt.year, dt.month, dt.day, 
            dt.hour, dt.minute, dt.second, 
            dt.microsecond, Config.TIMEZONE
        )

async def normalize_title(title):
    """Chu·∫©n h√≥a ti√™u ƒë·ªÅ tin t·ª©c ƒë·ªÉ so s√°nh"""
    if not title:
        return ""
    
    # Remove HTML tags if any
    title = re.sub(r'<[^>]+>', '', title)
    
    # Normalize unicode
    title = unicodedata.normalize('NFD', title)
    title = ''.join([c for c in title if unicodedata.category(c) != 'Mn'])
    
    # Convert to lowercase and remove extra spaces
    title = re.sub(r'\s+', ' ', title.lower().strip())
    
    # Remove special characters
    title = re.sub(r'[^\w\s]', '', title)
    
    return title

async def is_title_sent(normalized_title):
    """Ki·ªÉm tra xem ti√™u ƒë·ªÅ ƒë√£ ƒë∆∞·ª£c g·ª≠i ch∆∞a (d·ª±a tr√™n ti√™u ƒë·ªÅ chu·∫©n h√≥a)"""
    return await redis_client.sismember("sent_titles", normalized_title)

async def mark_title_sent(normalized_title):
    """ƒê√°nh d·∫•u ti√™u ƒë·ªÅ ƒë√£ ƒë∆∞·ª£c g·ª≠i"""
    await redis_client.sadd("sent_titles", normalized_title)
    await redis_client.expire("sent_titles", Config.REDIS_TTL)

# --- News Duplication Detection ---
async def get_recent_news_texts(days=Config.RECENT_NEWS_DAYS):
    """L·∫•y danh s√°ch tin g·∫ßn ƒë√¢y t·ª´ DB ƒë·ªÉ so s√°nh t√¨m tr√πng l·∫∑p"""
    try:
        async with pool.acquire() as conn:
            rows = await conn.fetch(
                f"SELECT title, summary FROM news_insights WHERE created_at > NOW() - INTERVAL '{days} days'"
            )
            # Gh√©p ti√™u ƒë·ªÅ v√† t√≥m t·∫Øt ƒë·ªÉ so s√°nh
            return [f"{row['title']} {row['summary']}" for row in rows]
    except Exception as e:
        logger.error(f"L·ªói khi l·∫•y tin g·∫ßn ƒë√¢y t·ª´ DB: {e}")
        return []

def is_duplicate_by_content(new_text, recent_texts, threshold=Config.DUPLICATE_THRESHOLD):
    """Ph√°t hi·ªán tin tr√πng l·∫∑p b·∫±ng TF-IDF v√† Cosine Similarity"""
    if not recent_texts:
        return False
    
    try:
        # Th√™m tin m·ªõi v√†o ƒë·∫ßu danh s√°ch ƒë·ªÉ vector h√≥a
        texts = [new_text] + recent_texts
        
        # T√≠nh vector TF-IDF
        vectorizer = TfidfVectorizer(
            lowercase=True, 
            stop_words="english",
            ngram_range=(1, 2),
            min_df=1
        ).fit_transform(texts)
        
        # Chuy·ªÉn sang m·∫£ng ƒë·ªÉ so s√°nh
        vectors = vectorizer.toarray()
        
        # T√≠nh cosine similarity gi·ªØa tin m·ªõi v√† c√°c tin c≈©
        sim_scores = cosine_similarity([vectors[0]], vectors[1:])[0]
        
        # Ki·ªÉm tra c√≥ tr√πng l·∫∑p kh√¥ng (similarity > threshold)
        max_similarity = max(sim_scores) if len(sim_scores) > 0 else 0
        is_duplicate = max_similarity > threshold
        
        if is_duplicate:
            logger.info(f"Ph√°t hi·ªán tin tr√πng l·∫∑p! Similarity: {max_similarity:.2f}, Threshold: {threshold}")
        
        return is_duplicate
    except Exception as e:
        logger.error(f"L·ªói khi ph√°t hi·ªán tin tr√πng l·∫∑p: {e}")
        return False  # N·∫øu l·ªói, coi nh∆∞ kh√¥ng tr√πng ƒë·ªÉ x·ª≠ l√Ω tin

# --- Function to update database to ensure all timestamps use timezone ---
async def ensure_db_timezone_columns():
    """ƒê·∫£m b·∫£o t·∫•t c·∫£ c√°c c·ªôt datetime trong DB ƒë·ªÅu l∆∞u timezone"""
    try:
        async with pool.acquire() as conn:
            # Ki·ªÉm tra c√°c b·∫£ng hi·ªán c√≥
            tables = await conn.fetch("""
                SELECT table_name FROM information_schema.tables 
                WHERE table_schema = 'public'
            """)
            
            for table in tables:
                table_name = table['table_name']
                # Ki·ªÉm tra c√°c c·ªôt timestamp
                columns = await conn.fetch("""
                    SELECT column_name, data_type 
                    FROM information_schema.columns 
                    WHERE table_name = $1 AND data_type LIKE '%timestamp%'
                """, table_name)
                
                for column in columns:
                    col_name = column['column_name']
                    data_type = column['data_type']
                    
                    # N·∫øu c·ªôt timestamp kh√¥ng c√≥ timezone, alter ƒë·ªÉ th√™m
                    if data_type == 'timestamp without time zone':
                        logger.info(f"C·∫≠p nh·∫≠t c·ªôt {table_name}.{col_name} sang timestamptz")
                        await conn.execute(f"""
                            ALTER TABLE {table_name} 
                            ALTER COLUMN {col_name} TYPE timestamp with time zone 
                            USING {col_name} AT TIME ZONE 'Asia/Ho_Chi_Minh'
                        """)
            
            logger.info("ƒê√£ ki·ªÉm tra v√† c·∫≠p nh·∫≠t c√°c c·ªôt timestamp trong DB")
    except Exception as e:
        logger.error(f"L·ªói khi c·∫≠p nh·∫≠t DB timestamp columns: {e}")

async def init_db():
    """Initialize the database with necessary tables"""
    global pool
    try:
        # Connect to the database
        pool = await asyncpg.create_pool(Config.DB_URL)
        
        # Create news_insights table if it doesn't exist
        async with pool.acquire() as conn:
            await conn.execute("""
                CREATE TABLE IF NOT EXISTS news_insights (
                    id SERIAL PRIMARY KEY,
                    title TEXT NOT NULL,
                    link TEXT UNIQUE NOT NULL,
                    summary TEXT,
                    sentiment TEXT,
                    ai_opinion TEXT,
                    is_hot_news BOOLEAN DEFAULT FALSE,
                    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
                )
            """)
            
            # Create approved_users table if it doesn't exist
            await conn.execute("""
                CREATE TABLE IF NOT EXISTS approved_users (
                    id SERIAL PRIMARY KEY,
                    user_id TEXT UNIQUE NOT NULL,
                    approved_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
                )
            """)
            
            # ƒê·∫£m b·∫£o admin lu√¥n c√≥ trong b·∫£ng approved_users
            await conn.execute(
                "INSERT INTO approved_users (user_id) VALUES ($1) ON CONFLICT (user_id) DO NOTHING",
                str(Config.ADMIN_ID)
            )
            
            # Load approved users from the database
            global approved_users
            rows = await conn.fetch("SELECT user_id FROM approved_users")
            approved_users = set(int(row['user_id']) for row in rows)
            # ƒê·∫£m b·∫£o admin lu√¥n trong set
            approved_users.add(Config.ADMIN_ID)
            
        # ƒê·∫£m b·∫£o t·∫•t c·∫£ c√°c c·ªôt timestamp ƒë·ªÅu l∆∞u timezone
        await ensure_db_timezone_columns()
            
        logger.info(f"Database initialized successfully. Loaded {len(approved_users)} approved users.")
        return True
    except Exception as e:
        logger.error(f"Error initializing database: {e}")
        return False

async def init_redis():
    """Initialize Redis connection"""
    global redis_client
    try:
        redis_client = aioredis.from_url(Config.REDIS_URL)
        
        # Load additional keywords from Redis if they exist
        global additional_keywords
        keywords_data = await redis_client.get("additional_keywords")
        if keywords_data:
            additional_keywords = pickle.loads(keywords_data)
            logger.info(f"Loaded {len(additional_keywords)} additional keywords from Redis")
        
        logger.info("Redis initialized successfully")
        return True
    except Exception as e:
        logger.error(f"Error initializing Redis: {e}")
        return False

async def clear_news_queues():
    """X√≥a t·∫•t c·∫£ tin t·ª©c trong queue khi kh·ªüi ƒë·ªông l·∫°i bot ƒë·ªÉ tr√°nh g·ª≠i l·∫°i tin c≈©"""
    try:
        # X√≥a c√°c queue tin t·ª©c
        await redis_client.delete("hot_news_queue")
        await redis_client.delete("news_queue")
        # Gi·ªØ l·∫°i ids ƒë√£ g·ª≠i ƒë·ªÉ tr√°nh tr√πng l·∫∑p
        logger.info("ƒê√£ x√≥a t·∫•t c·∫£ tin trong queue ƒë·ªÉ chu·∫©n b·ªã cho qu√©t m·ªõi")
    except Exception as e:
        logger.error(f"L·ªói khi x√≥a queue tin t·ª©c: {e}")

# --- Helper for rotating RSS feed index ---
async def get_current_feed_index():
    idx = await redis_client.get("current_feed_index")
    if idx is not None:
        return int(idx)
    return 0

async def set_current_feed_index(idx):
    await redis_client.set("current_feed_index", str(idx))

# --- Main Function ---

# Global application variable to store our bot instance
application = None

async def send_message_to_user(user_id, message, entry=None, is_hot_news=False):
    """Send a news message to a user"""
    try:
        # Chu·∫©n b·ªã n·ªôi dung tin nh·∫Øn
        title = getattr(entry, 'title', 'Kh√¥ng c√≥ ti√™u ƒë·ªÅ')
        link = getattr(entry, 'link', '#')
        # L·∫•y published date v·ªõi x·ª≠ l√Ω timezone
        published = getattr(entry, 'published', None)
        # N·∫øu published l√† string, convert sang datetime
        if isinstance(published, str):
            try:
                published = datetime.datetime.strptime(published, '%a, %d %b %Y %H:%M:%S %Z')
                # ƒê·∫£m b·∫£o published c√≥ timezone
                published = ensure_timezone_aware(published)
            except ValueError:
                try:
                    # Th·ª≠ v·ªõi format kh√°c (RSS feeds c√≥ th·ªÉ kh√°c nhau)
                    published = datetime.datetime.strptime(published, '%a, %d %b %Y %H:%M:%S %z')
                except ValueError:
                    # Fallback n·∫øu parse th·∫•t b·∫°i
                    published = None
        # Format date
        date = format_datetime(published) if published else format_datetime(None)
        # Extract domain from link
        domain = urlparse(link).netloc
        # Create message with emoji based on news type
        prefix = "üî• TIN N√ìNG: " if is_hot_news else "üì∞ TIN M·ªöI: "
        # Format message
        formatted_message = (
            f"{prefix}<b>{title}</b>\n\n"
            f"<pre>{message}</pre>\n\n"
            f"<i>Ngu·ªìn: {domain} ‚Ä¢ {date}</i>\n"
            f"<a href='{link}'>ƒê·ªçc chi ti·∫øt</a>"
        )
        # T·∫°o n√∫t ƒë·ªçc chi ti·∫øt
        keyboard = [[InlineKeyboardButton("ƒê·ªçc chi ti·∫øt", url=link)]]
        reply_markup = InlineKeyboardMarkup(keyboard)
        # Get the global application's bot
        global application
        if application and application.bot:
            bot = application.bot
        else:
            from telegram import Bot
            bot = Bot(token=Config.BOT_TOKEN)
        # Lu√¥n g·ª≠i tin nh·∫Øn text, kh√¥ng g·ª≠i ·∫£nh
        await bot.send_message(
            chat_id=user_id,
            text=formatted_message,
            reply_markup=reply_markup,
            parse_mode='HTML',
            disable_web_page_preview=False
        )
    except Exception as e:
        logger.error(f"L·ªói khi g·ª≠i tin t·ª©c cho user {user_id}: {e}")

# --- C√°c job ƒë·ªãnh k·ª≥ m·ªõi ---

async def fetch_and_cache_news(context: ContextTypes.DEFAULT_TYPE):
    """
    Job ch·∫°y m·ªói 10 ph√∫t ƒë·ªÉ qu√©t 1 RSS, l·ªçc tin v√† ƒë·∫©y v√†o queue (lu√¢n phi√™n t·ª´ng ngu·ªìn).
    """
    try:
        logger.info("ƒêang qu√©t 1 RSS v√† cache tin m·ªõi...")
        # X√≥a tin c≈© kh·ªèi DB
        await delete_old_news()
        # L·∫•y tin g·∫ßn ƒë√¢y t·ª´ DB ƒë·ªÉ ki·ªÉm tra tr√πng l·∫∑p n·ªôi dung
        recent_news_texts = await get_recent_news_texts()
        queued_count = 0
        skipped_count = 0
        hot_news_count = 0
        feeds = Config.FEED_URLS
        # L·∫•y index ngu·ªìn hi·ªán t·∫°i t·ª´ Redis
        feed_idx = await get_current_feed_index()
        feed_url = feeds[feed_idx % len(feeds)]
        logger.info(f"Qu√©t RSS: {feed_url}")
        entries = await parse_feed(feed_url)
        for entry in entries:
            try:
                if not is_recent_news(entry, days=Config.FETCH_LIMIT_DAYS):
                    continue
                if not is_relevant_news_smart(entry):
                    continue
                entry_id = getattr(entry, 'id', '') or getattr(entry, 'link', '')
                if await redis_client.sismember("news_queue_ids", entry_id):
                    skipped_count += 1
                    continue
                if await is_sent(entry_id) or await is_in_db(entry):
                    await redis_client.sadd("news_queue_ids", entry_id)
                    skipped_count += 1
                    continue
                entry_text = f"{getattr(entry, 'title', '')} {getattr(entry, 'summary', '')}"
                if is_duplicate_by_content(entry_text, recent_news_texts):
                    skipped_count += 1
                    continue
                recent_news_texts.append(entry_text)
                is_hot = is_hot_news_simple(entry)
                news_data = {
                    "id": entry_id,
                    "title": getattr(entry, "title", ""),
                    "link": getattr(entry, "link", ""),
                    "summary": getattr(entry, "summary", ""),
                    "published": getattr(entry, "published", ""),
                    "is_hot": is_hot,
                }
                if is_hot:
                    await redis_client.rpush("hot_news_queue", json.dumps(news_data))
                    hot_news_count += 1
                else:
                    await redis_client.rpush("news_queue", json.dumps(news_data))
                await redis_client.sadd("news_queue_ids", entry_id)
                await redis_client.expire("news_queue_ids", Config.REDIS_TTL)
                queued_count += 1
            except Exception as e:
                logger.warning(f"L·ªói khi x·ª≠ l√Ω tin t·ª´ feed {feed_url}: {e}")
        hot_queue_len = await redis_client.llen("hot_news_queue")
        normal_queue_len = await redis_client.llen("news_queue")
        logger.info(f"Qu√©t RSS ho√†n t·∫•t: ƒê√£ cache {queued_count} tin m·ªõi ({hot_news_count} tin n√≥ng), "
                   f"b·ªè qua {skipped_count} tin tr√πng l·∫∑p. "
                   f"S·ªë tin trong queue: {hot_queue_len} tin n√≥ng, {normal_queue_len} tin th∆∞·ªùng.")
        # TƒÉng index l√™n 1 cho l·∫ßn sau
        await set_current_feed_index((feed_idx + 1) % len(feeds))
    except Exception as e:
        logger.error(f"L·ªói trong job fetch_and_cache_news: {e}")

async def send_news_from_queue(context: ContextTypes.DEFAULT_TYPE):
    """
    Job ch·∫°y m·ªói 800s ƒë·ªÉ l·∫•y 1 tin t·ª´ queue v√† g·ª≠i cho user.
    ∆Øu ti√™n tin n√≥ng tr∆∞·ªõc.
    """
    try:
        # L·∫•y danh s√°ch ng∆∞·ªùi d√πng ƒë√£ ƒë∆∞·ª£c ph√™ duy·ªát
        approved_users_list = []
        try:
            async with pool.acquire() as conn:
                rows = await conn.fetch("SELECT user_id FROM approved_users")
                approved_users_list = [int(row['user_id']) for row in rows]
        except Exception as e:
            logger.error(f"L·ªói khi l·∫•y danh s√°ch approved users: {e}")
            return
            
        if not approved_users_list:
            logger.warning("Kh√¥ng c√≥ ng∆∞·ªùi d√πng n√†o ƒë∆∞·ª£c ph√™ duy·ªát ƒë·ªÉ g·ª≠i tin.")
            return
            
        # ∆Øu ti√™n l·∫•y tin n√≥ng tr∆∞·ªõc
        news_json = await redis_client.lpop("hot_news_queue")
        if not news_json:
            # N·∫øu kh√¥ng c√≥ tin n√≥ng, l·∫•y tin th∆∞·ªùng
            news_json = await redis_client.lpop("news_queue")
            
        if not news_json:
            logger.info("Kh√¥ng c√≤n tin trong c·∫£ hai queue. ƒê·ª£i chu k·ª≥ fetch ti·∫øp theo.")
            return
            
        # Parse JSON th√†nh dict
        news_data = json.loads(news_json)
        
        # Ph√¢n t√≠ch tin t·ª©c b·∫±ng AI
        domain = urlparse(news_data['link']).netloc if 'link' in news_data else 'N/A'
        prompt = f"""
        T√≥m t·∫Øt v√† ph√¢n t√≠ch tin t·ª©c sau cho nh√† ƒë·∫ßu t∆∞ ch·ª©ng kho√°n Vi·ªát Nam.
        \nTi√™u ƒë·ªÅ: {news_data.get('title', 'Kh√¥ng c√≥ ti√™u ƒë·ªÅ')}
        T√≥m t·∫Øt: {news_data.get('summary', 'Kh√¥ng c√≥ t√≥m t·∫Øt')}
        Ngu·ªìn: {domain}
        \n1. T√≥m t·∫Øt ng·∫Øn g·ªçn n·ªôi dung (2-3 c√¢u)
        2. Ph√¢n t√≠ch, ƒë√°nh gi√° t√°c ƒë·ªông ( 3-5 c√¢u ). C·∫£m x√∫c (T√≠ch c·ª±c/Ti√™u c·ª±c/Trung l·∫≠p)
        3. L·ªùi khuy√™n cho nh√† ƒë·∫ßu t∆∞ (1 c√¢u)
        """
        
        try:
            ai_summary = await analyze_news(prompt)
        except Exception as e:
            logger.error(f"L·ªói khi ph√¢n t√≠ch tin b·∫±ng AI: {e}")
            # N·∫øu kh√¥ng ph√¢n t√≠ch ƒë∆∞·ª£c, d√πng summary g·ªëc
            ai_summary = news_data.get('summary', 'Kh√¥ng c√≥ ph√¢n t√≠ch n√†o.')
            
        # T·∫°o ƒë·ªëi t∆∞·ª£ng entry t·ª´ news_data ƒë·ªÉ truy·ªÅn v√†o h√†m g·ª≠i
        class EntryObject:
            pass
            
        entry = EntryObject()
        for key, value in news_data.items():
            setattr(entry, key, value)
            
        # L∆∞u tin v√†o DB
        try:
            is_hot = news_data.get('is_hot', False)
            sentiment = await extract_sentiment(ai_summary) if is_hot else 'Trung l·∫≠p'
            await save_news(entry, ai_summary, sentiment, is_hot)
            
            # ƒê√°nh d·∫•u tin ƒë√£ ƒë∆∞·ª£c g·ª≠i
            await mark_sent(news_data.get('id', '') or news_data.get('link', ''))
        except Exception as e:
            logger.error(f"L·ªói khi l∆∞u tin v√†o DB: {e}")
            
        # G·ª≠i tin cho t·∫•t c·∫£ ng∆∞·ªùi d√πng
        sent_count = 0
        for user_id in approved_users_list:
            try:
                await send_message_to_user(user_id, ai_summary, entry, news_data.get('is_hot', False))
                sent_count += 1
            except Exception as e:
                logger.error(f"L·ªói khi g·ª≠i tin cho user {user_id}: {e}")
                
        logger.info(f"ƒê√£ g·ª≠i tin '{news_data.get('title', '')[:30]}...' cho {sent_count}/{len(approved_users_list)} ng∆∞·ªùi d√πng.")
        
    except Exception as e:
        logger.error(f"L·ªói trong job send_news_from_queue: {e}")

# Function to handle callback queries
async def button_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    
    # Handle different callback data
    if query.data == "view_keywords":
        # Reuse view_keywords_command logic
        user_id = update.effective_user.id
        
        if not await is_user_approved(user_id):
            await query.message.reply_text(
                "‚ùå B·∫°n ch∆∞a ƒë∆∞·ª£c ph√™ duy·ªát ƒë·ªÉ s·ª≠ d·ª•ng bot. G√µ /register ƒë·ªÉ ƒëƒÉng k√Ω."
            )
            return
        
        global additional_keywords
        default_keywords = Config.RELEVANT_KEYWORDS
        
        message = (
            f"üìã *Danh s√°ch t·ª´ kh√≥a hi·ªán t·∫°i*\n\n"
            f"*T·ª´ kh√≥a m·∫∑c ƒë·ªãnh ({len(default_keywords)})*: Bao g·ªìm c√°c t·ª´ kh√≥a v·ªÅ ch·ª©ng kho√°n, kinh t·∫ø, t√†i ch√≠nh...\n\n"
        )
        
        if additional_keywords:
            message += f"*T·ª´ kh√≥a b·ªï sung ({len(additional_keywords)})*:\n{', '.join(additional_keywords)}\n\n"
        else:
            message += "*T·ª´ kh√≥a b·ªï sung*: Ch∆∞a c√≥\n\n"
        
        message += (
            "S·ª≠ d·ª•ng /set_keywords ƒë·ªÉ th√™m t·ª´ kh√≥a b·ªï sung.\n"
            "S·ª≠ d·ª•ng /clear_keywords ƒë·ªÉ x√≥a t·∫•t c·∫£ t·ª´ kh√≥a b·ªï sung."
        )
        
        await query.message.reply_text(message, parse_mode='Markdown')
    
    elif query.data == "help":
        # Show help message
        await help_command(update, context)
    
    # Handle other callbacks
    elif query.data.startswith("approve_") or query.data.startswith("deny_"):
        await approve_user_callback(update, context)

def main():
    global application
    application = Application.builder().token(Config.BOT_TOKEN).build()

    # Initialize database and Redis
    loop = asyncio.get_event_loop()
    db_ok = loop.run_until_complete(init_db())
    redis_ok = loop.run_until_complete(init_redis())

    if not db_ok or not redis_ok:
        logger.error("Failed to initialize database or Redis. Exiting.")
        return

    # X√≥a queue c≈© khi kh·ªüi ƒë·ªông l·∫°i
    loop.run_until_complete(clear_news_queues())

    # Add command handlers
    application.add_handler(CommandHandler("start", start_command))
    application.add_handler(CommandHandler("help", help_command))
    application.add_handler(CommandHandler("register", register_user))
    application.add_handler(CommandHandler("keywords", view_keywords_command))
    application.add_handler(CommandHandler("set_keywords", set_keywords_command))
    application.add_handler(CommandHandler("clear_keywords", clear_keywords_command))

    # Add callback query handler
    application.add_handler(CallbackQueryHandler(button_callback))

    # Set up the job queue
    job_queue = application.job_queue
    
    # C·∫•u h√¨nh c√°c job ƒë·ªãnh k·ª≥ m·ªõi:
    # 1. Job qu√©t RSS m·ªói gi·ªù v√† cache tin
    job_queue.run_repeating(fetch_and_cache_news, interval=Config.HOURLY_JOB_INTERVAL, first=10)
    
    # 2. Job g·ª≠i tin t·ª´ queue m·ªói 800s
    job_queue.run_repeating(send_news_from_queue, interval=Config.NEWS_JOB_INTERVAL, first=30)
    
    # In th√¥ng tin job
    logger.info(f"ƒê√£ thi·∫øt l·∫≠p 2 job ƒë·ªãnh k·ª≥:\n"
                f"- Qu√©t RSS & cache: {Config.HOURLY_JOB_INTERVAL}s/l·∫ßn\n"
                f"- G·ª≠i tin t·ª´ queue: {Config.NEWS_JOB_INTERVAL}s/l·∫ßn")

    if Config.WEBHOOK_URL:
        webhook_port = int(os.environ.get("PORT", 8443))
        logger.info(f"Starting webhook on port {webhook_port} with URL: {Config.WEBHOOK_URL}")
        application.run_webhook(
            listen="0.0.0.0",
            port=webhook_port,
            url_path=Config.BOT_TOKEN,
            webhook_url=f"{Config.WEBHOOK_URL}/{Config.BOT_TOKEN}"
        )
    else:
        logger.info("Starting bot in polling mode")
        application.run_polling(allowed_updates=Update.ALL_TYPES)

if __name__ == "__main__":
    main()
